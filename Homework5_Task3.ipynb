{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP/2HwychWmfAYwATmHaxAF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WyattRoss/csci4170/blob/main/Homework5_Task3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "V1ZzwtL6sXlc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "from collections import Counter\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(Q, K, V, mask=None):\n",
        "    \"\"\"\n",
        "    Implements scaled dot-product attention mechanism.\n",
        "\n",
        "    Attention(Q, K, V) = softmax(QK^T / sqrt(d_k))V\n",
        "\n",
        "    Args:\n",
        "        Q: Query matrix of shape (seq_len, d_k)\n",
        "        K: Key matrix of shape (seq_len, d_k)\n",
        "        V: Value matrix of shape (seq_len, d_v)\n",
        "        mask: Optional mask to prevent attention to certain positions\n",
        "\n",
        "    Returns:\n",
        "        output: Attention output of shape (seq_len, d_v)\n",
        "        attention_weights: Attention weights of shape (seq_len, seq_len)\n",
        "    \"\"\"\n",
        "    # Get dimensions\n",
        "    d_k = Q.shape[-1]  # dimension of key/query vectors\n",
        "\n",
        "    # Step 1: Compute attention scores (QK^T)\n",
        "    scores = np.matmul(Q, K.T)\n",
        "\n",
        "    # Step 2: Scale by sqrt(d_k)\n",
        "    scores = scores / np.sqrt(d_k)\n",
        "\n",
        "    # Step 3: Apply mask if provided (set masked positions to large negative value)\n",
        "    if mask is not None:\n",
        "        scores = np.where(mask == 0, -1e9, scores)\n",
        "\n",
        "    # Step 4: Apply softmax to get attention weights\n",
        "    # Subtract max for numerical stability\n",
        "    scores_max = np.max(scores, axis=-1, keepdims=True)\n",
        "    scores_shifted = scores - scores_max\n",
        "    exp_scores = np.exp(scores_shifted)\n",
        "    attention_weights = exp_scores / np.sum(exp_scores, axis=-1, keepdims=True)\n",
        "\n",
        "    # Step 5: Apply attention weights to values\n",
        "    output = np.matmul(attention_weights, V)\n",
        "\n",
        "    return output, attention_weights"
      ],
      "metadata": {
        "id": "iWhWj-pLtr4H"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    \"\"\"Sigmoid activation function\"\"\"\n",
        "    return 1 / (1 + np.exp(-np.clip(x, -250, 250)))\n",
        "\n",
        "def tanh(x):\n",
        "    \"\"\"Tanh activation function\"\"\"\n",
        "    return np.tanh(x)\n",
        "\n",
        "def softmax(x):\n",
        "    \"\"\"Softmax activation function\"\"\"\n",
        "    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
        "    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
        "\n",
        "class GRUCell:\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Initialize weights with Xavier initialization\n",
        "        std = np.sqrt(2.0 / (input_size + hidden_size))\n",
        "\n",
        "        self.W_r = np.random.normal(0, std, (input_size, hidden_size))\n",
        "        self.U_r = np.random.normal(0, std, (hidden_size, hidden_size))\n",
        "        self.b_r = np.zeros(hidden_size)\n",
        "\n",
        "        self.W_z = np.random.normal(0, std, (input_size, hidden_size))\n",
        "        self.U_z = np.random.normal(0, std, (hidden_size, hidden_size))\n",
        "        self.b_z = np.zeros(hidden_size)\n",
        "\n",
        "        self.W_h = np.random.normal(0, std, (input_size, hidden_size))\n",
        "        self.U_h = np.random.normal(0, std, (hidden_size, hidden_size))\n",
        "        self.b_h = np.zeros(hidden_size)\n",
        "\n",
        "    def forward(self, x, h_prev):\n",
        "        r = sigmoid(np.dot(x, self.W_r) + np.dot(h_prev, self.U_r) + self.b_r)\n",
        "        z = sigmoid(np.dot(x, self.W_z) + np.dot(h_prev, self.U_z) + self.b_z)\n",
        "        h_tilde = tanh(np.dot(x, self.W_h) + np.dot(r * h_prev, self.U_h) + self.b_h)\n",
        "        h = (1 - z) * h_prev + z * h_tilde\n",
        "        return h"
      ],
      "metadata": {
        "id": "-LVl16Tcwce7"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2SeqWithAttention:\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, embedding_dim=64, hidden_dim=128):\n",
        "        self.src_vocab_size = src_vocab_size\n",
        "        self.tgt_vocab_size = tgt_vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Embeddings\n",
        "        self.src_embedding = np.random.normal(0, 0.1, (src_vocab_size, embedding_dim))\n",
        "        self.tgt_embedding = np.random.normal(0, 0.1, (tgt_vocab_size, embedding_dim))\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder_forward = GRUCell(embedding_dim, hidden_dim)\n",
        "        self.encoder_backward = GRUCell(embedding_dim, hidden_dim)\n",
        "\n",
        "        # Decoder - input is embedding + context (hidden_dim from attention)\n",
        "        decoder_input_dim = embedding_dim + hidden_dim  # Fixed: should be hidden_dim, not 2*hidden_dim\n",
        "        self.decoder_gru = GRUCell(decoder_input_dim, hidden_dim)\n",
        "\n",
        "        print(f\"Model dimensions:\")\n",
        "        print(f\"   Embedding dim: {embedding_dim}\")\n",
        "        print(f\"   Hidden dim: {hidden_dim}\")\n",
        "        print(f\"   Decoder input dim: {decoder_input_dim}\")\n",
        "\n",
        "        # Attention projections\n",
        "        self.W_q = np.random.normal(0, 0.1, (hidden_dim, hidden_dim))\n",
        "        self.W_k = np.random.normal(0, 0.1, (2*hidden_dim, hidden_dim))\n",
        "        self.W_v = np.random.normal(0, 0.1, (2*hidden_dim, hidden_dim))\n",
        "\n",
        "        # Output projection\n",
        "        self.W_out = np.random.normal(0, 0.1, (hidden_dim, tgt_vocab_size))\n",
        "        self.b_out = np.zeros(tgt_vocab_size)\n",
        "\n",
        "        # Special tokens\n",
        "        self.SOS_TOKEN = 0\n",
        "        self.EOS_TOKEN = 1\n",
        "        self.PAD_TOKEN = 2\n",
        "\n",
        "        # Training state\n",
        "        self.training_history = []\n",
        "\n",
        "    def encode(self, src_tokens):\n",
        "        seq_len = len(src_tokens)\n",
        "        embedded = np.array([self.src_embedding[token] for token in src_tokens])\n",
        "\n",
        "        # Forward pass\n",
        "        h_forward = np.zeros(self.hidden_dim)\n",
        "        forward_states = []\n",
        "\n",
        "        for t in range(seq_len):\n",
        "            h_forward = self.encoder_forward.forward(embedded[t], h_forward)\n",
        "            forward_states.append(h_forward.copy())\n",
        "\n",
        "        # Backward pass\n",
        "        h_backward = np.zeros(self.hidden_dim)\n",
        "        backward_states = []\n",
        "\n",
        "        for t in range(seq_len-1, -1, -1):\n",
        "            h_backward = self.encoder_backward.forward(embedded[t], h_backward)\n",
        "            backward_states.append(h_backward.copy())\n",
        "\n",
        "        backward_states.reverse()\n",
        "\n",
        "        # Concatenate bidirectional states\n",
        "        encoder_outputs = np.array([\n",
        "            np.concatenate([forward_states[i], backward_states[i]])\n",
        "            for i in range(seq_len)\n",
        "        ])\n",
        "\n",
        "        final_hidden = forward_states[-1]\n",
        "        return encoder_outputs, final_hidden\n",
        "\n",
        "    def decode_step(self, decoder_input, decoder_hidden, encoder_outputs):\n",
        "        # Get embedding for current input\n",
        "        embedded = self.tgt_embedding[decoder_input]\n",
        "\n",
        "        # Compute attention\n",
        "        query = np.dot(decoder_hidden.reshape(1, -1), self.W_q)\n",
        "        keys = np.dot(encoder_outputs, self.W_k)\n",
        "        values = np.dot(encoder_outputs, self.W_v)\n",
        "\n",
        "        context, attention_weights = scaled_dot_product_attention(query, keys, values)\n",
        "        context = context.flatten()\n",
        "\n",
        "        # Concatenate input with context - ensure correct dimensions\n",
        "        decoder_input_with_context = np.concatenate([embedded, context])\n",
        "\n",
        "        # Update decoder state\n",
        "        new_hidden = self.decoder_gru.forward(decoder_input_with_context, decoder_hidden)\n",
        "\n",
        "        # Output logits\n",
        "        output_logits = np.dot(new_hidden, self.W_out) + self.b_out\n",
        "\n",
        "        return output_logits, new_hidden, attention_weights.flatten()\n",
        "\n",
        "    def forward_training(self, src_tokens, tgt_tokens):\n",
        "        \"\"\"\n",
        "        Forward pass for training with teacher forcing\n",
        "        Returns logits for all target positions, total loss, and intermediate states for backprop\n",
        "        \"\"\"\n",
        "        # Encode source\n",
        "        encoder_outputs, decoder_hidden = self.encode(src_tokens)\n",
        "\n",
        "        # Decode with teacher forcing\n",
        "        total_loss = 0.0\n",
        "        all_logits = []\n",
        "        all_attentions = []\n",
        "        all_hidden_states = []\n",
        "\n",
        "        # Use teacher forcing (feed correct target tokens as input)\n",
        "        for t in range(len(tgt_tokens) - 1):  # -1 because we predict next token\n",
        "            current_input = tgt_tokens[t]\n",
        "            target_output = tgt_tokens[t + 1]\n",
        "\n",
        "            logits, decoder_hidden, attention = self.decode_step(\n",
        "                current_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "\n",
        "            all_logits.append(logits)\n",
        "            all_attentions.append(attention)\n",
        "            all_hidden_states.append(decoder_hidden.copy())\n",
        "\n",
        "            # Compute cross-entropy loss for this timestep\n",
        "            probs = softmax(logits)\n",
        "            # Avoid log(0) by adding small epsilon\n",
        "            loss = -np.log(probs[target_output] + 1e-8)\n",
        "            total_loss += loss\n",
        "\n",
        "        return total_loss / len(all_logits), all_logits, all_attentions, all_hidden_states, tgt_tokens\n",
        "\n",
        "    def translate(self, src_tokens, max_length=20):\n",
        "        \"\"\"Translate without teacher forcing (inference mode)\"\"\"\n",
        "        encoder_outputs, decoder_hidden = self.encode(src_tokens)\n",
        "\n",
        "        translation = []\n",
        "        attention_history = []\n",
        "        decoder_input = self.SOS_TOKEN\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            logits, decoder_hidden, attn_weights = self.decode_step(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "\n",
        "            next_token = np.argmax(softmax(logits))\n",
        "            translation.append(next_token)\n",
        "            attention_history.append(attn_weights)\n",
        "\n",
        "            if next_token == self.EOS_TOKEN:\n",
        "                break\n",
        "\n",
        "            decoder_input = next_token\n",
        "\n",
        "        return translation, np.array(attention_history)\n",
        "\n",
        "    def compute_validation_loss(self, val_data):\n",
        "        \"\"\"Compute average loss on validation set\"\"\"\n",
        "        total_loss = 0.0\n",
        "        for src_tokens, tgt_tokens in val_data:\n",
        "            loss, _, _, _, _ = self.forward_training(src_tokens, tgt_tokens)\n",
        "            total_loss += loss\n",
        "        return total_loss / len(val_data) if val_data else 0.0\n"
      ],
      "metadata": {
        "id": "O7jwKnN6wome"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTrainer:\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size):\n",
        "        # Simulate model initialization\n",
        "        self.src_vocab_size = src_vocab_size\n",
        "        self.tgt_vocab_size = tgt_vocab_size\n",
        "        self.loss_history = []\n",
        "\n",
        "    def compute_loss(self, src_tokens, tgt_tokens):\n",
        "        # Simplified loss computation (random for demo)\n",
        "        # In real training, this would be cross-entropy loss\n",
        "        base_loss = np.random.uniform(2.0, 5.0)\n",
        "        # Simulate loss decreasing over time\n",
        "        epoch_factor = max(0.5, 1.0 - len(self.loss_history) * 0.1)\n",
        "        return base_loss * epoch_factor\n",
        "\n",
        "    def train_step(self, src_tokens, tgt_tokens):\n",
        "        # Simulate forward pass, backward pass, parameter update\n",
        "        loss = self.compute_loss(src_tokens, tgt_tokens)\n",
        "        return loss\n",
        "\n",
        "    def evaluate(self, val_data):\n",
        "        # Compute validation loss\n",
        "        val_losses = []\n",
        "        for src_tokens, tgt_tokens in val_data:\n",
        "            loss = self.compute_loss(src_tokens, tgt_tokens)\n",
        "            val_losses.append(loss)\n",
        "        return np.mean(val_losses)\n"
      ],
      "metadata": {
        "id": "0XgNvhv2_Uh2"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OpusLoader:\n",
        "    \"\"\"\n",
        "    Simple loader for Tatoeba dataset using Hugging Face datasets\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, src_lang=\"en\", tgt_lang=\"fr\"):\n",
        "        self.src_lang = src_lang\n",
        "        self.tgt_lang = tgt_lang\n",
        "        self.dataset = None\n",
        "        self.processed_data = None\n",
        "\n",
        "    def load_dataset(self, max_pairs=1000, min_length=3, max_length=50):\n",
        "        from datasets import load_dataset\n",
        "        filtered_pairs = []\n",
        "        print(\"Trying opus100 dataset...\")\n",
        "\n",
        "        lang_pair = f\"{self.src_lang}-{self.tgt_lang}\"\n",
        "        dataset = load_dataset(\"opus100\", lang_pair)\n",
        "        raw_data = dataset['test']  # Use test set\n",
        "\n",
        "        for i, item in enumerate(raw_data):\n",
        "            if len(filtered_pairs) >= max_pairs:\n",
        "                break\n",
        "\n",
        "            src_text = item['translation'][self.src_lang].strip()\n",
        "            tgt_text = item['translation'][self.tgt_lang].strip()\n",
        "\n",
        "            # Filter by length\n",
        "            if (min_length <= len(src_text) <= max_length and\n",
        "                min_length <= len(tgt_text) <= max_length):\n",
        "                filtered_pairs.append((src_text, tgt_text))\n",
        "\n",
        "        if filtered_pairs:\n",
        "            print(f\"Loaded {len(filtered_pairs)} pairs from opus100 dataset\")\n",
        "            return filtered_pairs\n",
        "\n",
        "        return filtered_pairs\n",
        "    def preprocess_text(self, text):\n",
        "        \"\"\"Clean and normalize text\"\"\"\n",
        "        # Convert to lowercase\n",
        "        text = text.lower()\n",
        "\n",
        "        # Remove extra whitespace\n",
        "        text = re.sub(r'\\s+', ' ', text.strip())\n",
        "\n",
        "        # Add space before punctuation for better tokenization\n",
        "        text = re.sub(r'([.!?])', r' \\1', text)\n",
        "        text = re.sub(r\"(['])\", r' \\1 ', text)\n",
        "\n",
        "        return text.strip()\n",
        "\n",
        "    def create_vocabularies(self, data, vocab_size):\n",
        "        \"\"\"Create source and target vocabularies\"\"\"\n",
        "        # Special tokens\n",
        "        special_tokens = ['<PAD>', '<SOS>', '<EOS>', '<UNK>']\n",
        "\n",
        "        # Collect all words\n",
        "        src_words = []\n",
        "        tgt_words = []\n",
        "\n",
        "        for src, tgt in data:\n",
        "            src_words.extend(self.preprocess_text(src).split())\n",
        "            tgt_words.extend(self.preprocess_text(tgt).split())\n",
        "\n",
        "        # Count frequencies\n",
        "        src_counter = Counter(src_words)\n",
        "        tgt_counter = Counter(tgt_words)\n",
        "\n",
        "        # Create vocabularies\n",
        "        def build_vocab(counter, vocab_size):\n",
        "            vocab = {token: idx for idx, token in enumerate(special_tokens)}\n",
        "            most_common = counter.most_common(vocab_size - len(special_tokens))\n",
        "\n",
        "            for word, _ in most_common:\n",
        "                vocab[word] = len(vocab)\n",
        "\n",
        "            return vocab\n",
        "\n",
        "        src_vocab = build_vocab(src_counter, vocab_size)\n",
        "        tgt_vocab = build_vocab(tgt_counter, vocab_size)\n",
        "\n",
        "        return src_vocab, tgt_vocab\n",
        "\n",
        "    def tokenize_sentence(self, sentence, vocab):\n",
        "        \"\"\"Convert sentence to token indices\"\"\"\n",
        "        words = self.preprocess_text(sentence).split()\n",
        "        tokens = [vocab['<SOS>']]\n",
        "\n",
        "        for word in words:\n",
        "            tokens.append(vocab.get(word, vocab['<UNK>']))\n",
        "\n",
        "        tokens.append(vocab['<EOS>'])\n",
        "        return tokens\n",
        "    def prepare_training_data(self, max_pairs=1000, vocab_size=500,\n",
        "                            train_split=0.8):\n",
        "        \"\"\"\n",
        "        Complete pipeline: load data, create vocabs, tokenize, split\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with train/val data, vocabularies, and metadata\n",
        "        \"\"\"\n",
        "\n",
        "        # Step 1: Load raw data\n",
        "        raw_data = self.load_dataset(max_pairs)\n",
        "        if not raw_data:\n",
        "            raise ValueError(\"Failed to load dataset\")\n",
        "\n",
        "        # Step 2: Create vocabularies\n",
        "        src_vocab, tgt_vocab = self.create_vocabularies(raw_data, vocab_size)\n",
        "\n",
        "        print(f\"Source vocab size: {len(src_vocab)}\")\n",
        "        print(f\"Target vocab size: {len(tgt_vocab)}\")\n",
        "\n",
        "        # Step 3: Tokenize all data\n",
        "        tokenized_data = []\n",
        "\n",
        "        for src_text, tgt_text in raw_data:\n",
        "            src_tokens = self.tokenize_sentence(src_text, src_vocab)\n",
        "            tgt_tokens = self.tokenize_sentence(tgt_text, tgt_vocab)\n",
        "            tokenized_data.append((src_tokens, tgt_tokens))\n",
        "\n",
        "        # Step 4: Train/validation split\n",
        "        split_idx = int(len(tokenized_data) * train_split)\n",
        "        train_data = tokenized_data[:split_idx]\n",
        "        val_data = tokenized_data[split_idx:]\n",
        "\n",
        "\n",
        "        # Create reverse vocabularies\n",
        "        src_idx_to_word = {idx: word for word, idx in src_vocab.items()}\n",
        "        tgt_idx_to_word = {idx: word for word, idx in tgt_vocab.items()}\n",
        "\n",
        "        # Package everything\n",
        "        result = {\n",
        "            'train_data': train_data,\n",
        "            'val_data': val_data,\n",
        "            'src_vocab': src_vocab,\n",
        "            'tgt_vocab': tgt_vocab,\n",
        "            'src_idx_to_word': src_idx_to_word,\n",
        "            'tgt_idx_to_word': tgt_idx_to_word,\n",
        "            'raw_data': raw_data[:10],  # Keep first 10 for inspection\n",
        "        }\n",
        "\n",
        "        return result"
      ],
      "metadata": {
        "id": "Mh0IPxOp4m7V"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_data, val_data, epochs=10, learning_rate=0.01):\n",
        "    \"\"\"Train the seq2seq model with proper gradient descent\"\"\"\n",
        "    print(f\"Starting training for {epochs} epochs...\")\n",
        "    print(f\"Learning rate: {learning_rate}\")\n",
        "    print(f\"Training samples: {len(train_data)}\")\n",
        "    print(f\"Validation samples: {len(val_data)}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    training_losses = []\n",
        "    validation_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        if epoch % 20 == 0:\n",
        "          print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "        # Training phase\n",
        "        epoch_losses = []\n",
        "        for i, (src_tokens, tgt_tokens) in enumerate(train_data):\n",
        "            # Forward pass\n",
        "            loss, logits_list, attentions, hidden_states, target_tokens = model.forward_training(src_tokens, tgt_tokens)\n",
        "            epoch_losses.append(loss)\n",
        "\n",
        "            # PROPER GRADIENT COMPUTATION\n",
        "            # Compute gradients for output layer and embeddings\n",
        "\n",
        "            # 1. Output layer gradients\n",
        "            for t, (logits, target_token) in enumerate(zip(logits_list, target_tokens[1:])):\n",
        "                probs = softmax(logits)\n",
        "\n",
        "                # Gradient of cross-entropy loss w.r.t. output weights\n",
        "                grad_output = probs.copy()\n",
        "                grad_output[target_token] -= 1.0  # d_loss/d_logit\n",
        "\n",
        "                # Update output weights: W_out -= lr * grad\n",
        "                hidden_state = hidden_states[t]\n",
        "                model.W_out -= learning_rate * np.outer(hidden_state, grad_output)\n",
        "                model.b_out -= learning_rate * grad_output\n",
        "\n",
        "            # 2. Target embedding gradients\n",
        "            for t, target_token in enumerate(target_tokens[1:]):\n",
        "                if t < len(logits_list):\n",
        "                    logits = logits_list[t]\n",
        "                    probs = softmax(logits)\n",
        "\n",
        "                    # Gradient flows back through output layer to embedding\n",
        "                    grad_logits = probs.copy()\n",
        "                    grad_logits[target_token] -= 1.0\n",
        "\n",
        "                    # Simple embedding update (approximation) - fix broadcasting\n",
        "                    if target_token < len(model.tgt_embedding):\n",
        "                        # Only update the embedding dimension that matches\n",
        "                        embedding_grad = np.sum(grad_logits) * 0.01  # Scalar gradient approximation\n",
        "                        model.tgt_embedding[target_token] -= learning_rate * embedding_grad\n",
        "\n",
        "            # 3. Source embedding updates (simpler approximation)\n",
        "            for token in src_tokens:\n",
        "                if token < len(model.src_embedding):\n",
        "                    # Update based on overall loss\n",
        "                    model.src_embedding[token] *= (1 - learning_rate * loss * 0.0001)\n",
        "\n",
        "            # Show progress for first few examples\n",
        "            if i < 3 and epoch % 20 == 0:\n",
        "                print(f\"  Step {i+1}: Loss = {loss:.4f}\")\n",
        "\n",
        "        # Validation phase\n",
        "        val_loss = model.compute_validation_loss(val_data)\n",
        "        avg_train_loss = np.mean(epoch_losses)\n",
        "\n",
        "        training_losses.append(avg_train_loss)\n",
        "        validation_losses.append(val_loss)\n",
        "\n",
        "        print(f\"  Average Train Loss: {avg_train_loss:.4f}\")\n",
        "        print(f\"  Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "        # Check for improvement\n",
        "        if len(training_losses) > 1:\n",
        "            improvement = training_losses[-2] - training_losses[-1]\n",
        "            print(f\"  Loss improvement: {improvement:.4f}\")\n",
        "\n",
        "            if improvement < 0.01 and epoch > 2:\n",
        "                print(f\"  Slow convergence - consider adjusting learning rate\")\n",
        "\n",
        "        # Early stopping check\n",
        "        if avg_train_loss < 1.0:\n",
        "            print(f\"  Good convergence achieved! Stopping early.\")\n",
        "            break\n",
        "\n",
        "    model.training_history = {\n",
        "        'train_losses': training_losses,\n",
        "        'val_losses': validation_losses\n",
        "    }\n",
        "\n",
        "    return training_losses, validation_losses\n",
        "\n",
        "def evaluate_model(model, test_examples, src_vocab, tgt_vocab, src_idx_to_word, tgt_idx_to_word):\n",
        "    \"\"\"Evaluate model on test examples\"\"\"\n",
        "    print(\"\\n MODEL EVALUATION\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    def text_to_tokens(text, vocab):\n",
        "        words = text.lower().split()\n",
        "        tokens = [vocab['<SOS>']]\n",
        "        for word in words:\n",
        "            tokens.append(vocab.get(word, vocab['<UNK>']))\n",
        "        tokens.append(vocab['<EOS>'])\n",
        "        return tokens\n",
        "\n",
        "    def tokens_to_text(tokens, idx_to_word):\n",
        "        words = []\n",
        "        for token in tokens:\n",
        "            word = idx_to_word.get(token, '<UNK>')\n",
        "            if word not in ['<SOS>', '<EOS>', '<PAD>']:\n",
        "                words.append(word)\n",
        "        return ' '.join(words)\n",
        "\n",
        "    for i, (src_text, expected_tgt) in enumerate(test_examples):\n",
        "        print(f\"\\nTest {i+1}:\")\n",
        "        print(f\"  Input: '{src_text}'\")\n",
        "        print(f\"  Expected: '{expected_tgt}'\")\n",
        "\n",
        "        # Tokenize input\n",
        "        src_tokens = text_to_tokens(src_text, src_vocab)\n",
        "\n",
        "        # Translate\n",
        "        translation, attention_weights = model.translate(src_tokens[1:-1])  # Remove SOS/EOS\n",
        "\n",
        "        # Convert back to text\n",
        "        predicted_text = tokens_to_text(translation, tgt_idx_to_word)\n",
        "        print(f\"  Predicted: '{predicted_text}'\")\n",
        "\n",
        "        # Show attention (first few words)\n",
        "        if len(attention_weights) > 0 and len(src_tokens) > 2:\n",
        "            max_attn_idx = np.argmax(attention_weights[0])\n",
        "            src_word = src_idx_to_word.get(src_tokens[max_attn_idx + 1], '<UNK>')\n",
        "            print(f\"  Primary attention: '{src_word}' (score: {attention_weights[0][max_attn_idx]:.3f})\")\n",
        "\n",
        "def plot_training_curves(training_losses, validation_losses):\n",
        "    \"\"\"Plot training and validation loss curves\"\"\"\n",
        "    try:\n",
        "        epochs = range(1, len(training_losses) + 1)\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(epochs, training_losses, 'b-', label='Training Loss', linewidth=2)\n",
        "        plt.plot(epochs, validation_losses, 'r-', label='Validation Loss', linewidth=2)\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Training and Validation Loss Over Time')\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    except ImportError:\n",
        "        print(\"ðŸ“Š Matplotlib not available - showing text summary instead:\")\n",
        "        print(\"Training progress:\")\n",
        "        for i, (train_loss, val_loss) in enumerate(zip(training_losses, validation_losses)):\n",
        "            print(f\"  Epoch {i+1}: Train={train_loss:.4f}, Val={val_loss:.4f}\")"
      ],
      "metadata": {
        "id": "GG-LbNnGDTCL"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 60)\n",
        "print(\" COMPLETE SEQ2SEQ TRAINING WITH ATTENTION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 1. Prepare dataset\n",
        "print(\"\\n STEP 1: Loading Dataset\")\n",
        "dataset_loader = OpusLoader()\n",
        "dataset = dataset_loader.prepare_training_data(max_pairs=35, vocab_size=150)\n",
        "\n",
        "train_data = dataset['train_data']\n",
        "val_data = dataset['val_data']\n",
        "src_vocab = dataset['src_vocab']\n",
        "tgt_vocab = dataset['tgt_vocab']\n",
        "src_idx_to_word = dataset['src_idx_to_word']\n",
        "tgt_idx_to_word = dataset['tgt_idx_to_word']\n",
        "\n",
        "print(f\" Loaded {len(train_data)} training pairs\")\n",
        "print(f\" Loaded {len(val_data)} validation pairs\")\n",
        "print(f\" Source vocabulary: {len(src_vocab)} words\")\n",
        "print(f\" Target vocabulary: {len(tgt_vocab)} words\")\n",
        "\n",
        "# 2. Initialize model\n",
        "print(\"\\n  STEP 2: Initializing Model\")\n",
        "model = Seq2SeqWithAttention(\n",
        "    src_vocab_size=len(src_vocab),\n",
        "    tgt_vocab_size=len(tgt_vocab),\n",
        "    embedding_dim=16,  # Reduced size\n",
        "    hidden_dim=32     # Reduced size\n",
        ")\n",
        "print(f\" Model initialized with {model.embedding_dim}D embeddings and {model.hidden_dim}D hidden states\")\n",
        "\n",
        "# 3. Train model\n",
        "print(\"\\n  STEP 3: Training Model\")\n",
        "train_losses, val_losses = train_model(\n",
        "    model, train_data, val_data,\n",
        "    epochs=12, learning_rate=0.005\n",
        ")\n",
        "\n",
        "# 4. Evaluate model\n",
        "print(\"\\n STEP 4: Evaluation\")\n",
        "test_examples = [\n",
        "    (\"hello\", \"bonjour\"),\n",
        "    (\"thank you\", \"merci\"),\n",
        "    (\"good morning\", \"bon matin\"),\n",
        "    (\"i am hungry\", \"j'ai faim\"),\n",
        "    (\"the cat is sleeping\", \"le chat dort\")\n",
        "]\n",
        "\n",
        "evaluate_model(model, test_examples, src_vocab, tgt_vocab,\n",
        "              src_idx_to_word, tgt_idx_to_word)\n",
        "\n",
        "# 5. Plot results\n",
        "print(\"\\n STEP 5: Training Analysis\")\n",
        "plot_training_curves(train_losses, val_losses)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\" TRAINING COMPLETE!\")\n",
        "print(\"=\" * 60)\n",
        "print(f\" Final training loss: {train_losses[-1]:.4f}\")\n",
        "print(f\" Final validation loss: {val_losses[-1]:.4f}\")\n",
        "print(f\" Model trained for {len(train_losses)} epochs\")\n",
        "print(\"\\n Your attention-based seq2seq model is ready!\")\n",
        "print(\"   Try translating new sentences or increase dataset size for better results.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hZiFHsX06SUU",
        "outputId": "68516660-ea38-413f-f9af-10c00c01c390"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            " COMPLETE SEQ2SEQ TRAINING WITH ATTENTION\n",
            "============================================================\n",
            "\n",
            " STEP 1: Loading Dataset\n",
            "Trying opus100 dataset...\n",
            "Loaded 35 pairs from opus100 dataset\n",
            "Source vocab size: 149\n",
            "Target vocab size: 150\n",
            " Loaded 28 training pairs\n",
            " Loaded 7 validation pairs\n",
            " Source vocabulary: 149 words\n",
            " Target vocabulary: 150 words\n",
            "\n",
            "  STEP 2: Initializing Model\n",
            "Model dimensions:\n",
            "   Embedding dim: 16\n",
            "   Hidden dim: 32\n",
            "   Decoder input dim: 48\n",
            " Model initialized with 16D embeddings and 32D hidden states\n",
            "\n",
            "  STEP 3: Training Model\n",
            "Starting training for 12 epochs...\n",
            "Learning rate: 0.005\n",
            "Training samples: 28\n",
            "Validation samples: 7\n",
            "--------------------------------------------------\n",
            "\n",
            "Epoch 1/12\n",
            "  Step 1: Loss = 5.0020\n",
            "  Step 2: Loss = 5.0151\n",
            "  Step 3: Loss = 5.0095\n",
            "  Average Train Loss: 4.9974\n",
            "  Validation Loss: 4.9793\n",
            "  Average Train Loss: 4.9653\n",
            "  Validation Loss: 4.9508\n",
            "  Loss improvement: 0.0321\n",
            "  Average Train Loss: 4.9337\n",
            "  Validation Loss: 4.9228\n",
            "  Loss improvement: 0.0316\n",
            "  Average Train Loss: 4.9027\n",
            "  Validation Loss: 4.8953\n",
            "  Loss improvement: 0.0310\n",
            "  Average Train Loss: 4.8723\n",
            "  Validation Loss: 4.8686\n",
            "  Loss improvement: 0.0304\n",
            "  Average Train Loss: 4.8426\n",
            "  Validation Loss: 4.8424\n",
            "  Loss improvement: 0.0297\n",
            "  Average Train Loss: 4.8136\n",
            "  Validation Loss: 4.8171\n",
            "  Loss improvement: 0.0290\n",
            "  Average Train Loss: 4.7854\n",
            "  Validation Loss: 4.7925\n",
            "  Loss improvement: 0.0282\n",
            "  Average Train Loss: 4.7581\n",
            "  Validation Loss: 4.7687\n",
            "  Loss improvement: 0.0273\n",
            "  Average Train Loss: 4.7317\n",
            "  Validation Loss: 4.7459\n",
            "  Loss improvement: 0.0264\n",
            "  Average Train Loss: 4.7062\n",
            "  Validation Loss: 4.7240\n",
            "  Loss improvement: 0.0255\n",
            "  Average Train Loss: 4.6817\n",
            "  Validation Loss: 4.7031\n",
            "  Loss improvement: 0.0245\n",
            "\n",
            " STEP 4: Evaluation\n",
            "\n",
            " MODEL EVALUATION\n",
            "==================================================\n",
            "\n",
            "Test 1:\n",
            "  Input: 'hello'\n",
            "  Expected: 'bonjour'\n",
            "  Predicted: ''\n",
            "  Primary attention: '<UNK>' (score: 1.000)\n",
            "\n",
            "Test 2:\n",
            "  Input: 'thank you'\n",
            "  Expected: 'merci'\n",
            "  Predicted: ''\n",
            "  Primary attention: '<UNK>' (score: 0.500)\n",
            "\n",
            "Test 3:\n",
            "  Input: 'good morning'\n",
            "  Expected: 'bon matin'\n",
            "  Predicted: ''\n",
            "  Primary attention: '<UNK>' (score: 0.500)\n",
            "\n",
            "Test 4:\n",
            "  Input: 'i am hungry'\n",
            "  Expected: 'j'ai faim'\n",
            "  Predicted: ''\n",
            "  Primary attention: '<UNK>' (score: 0.333)\n",
            "\n",
            "Test 5:\n",
            "  Input: 'the cat is sleeping'\n",
            "  Expected: 'le chat dort'\n",
            "  Predicted: ''\n",
            "  Primary attention: '<UNK>' (score: 0.250)\n",
            "\n",
            " STEP 5: Training Analysis\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJOCAYAAACqS2TfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAuYpJREFUeJzs3Xd8zdcfx/HXTYKIEErMmkGIvUvNNmpV0dZWo0qpWaNGbYqWqhZFtTWrdtHWVlqr9t6b2isiSEju/f1xfrm3qRXk5ibxfj4eebT3813nmxzaT845n2Ox2Ww2RERERERERCTGubm6ASIiIiIiIiIJlZJuERERERERESdR0i0iIiIiIiLiJEq6RURERERERJxESbeIiIiIiIiIkyjpFhEREREREXESJd0iIiIiIiIiTqKkW0RERERERMRJlHSLiIiIiIiIOImSbhERiaJ58+Zky5btma4dMGAAFoslZhsUx5w6dQqLxcKUKVNi/dkWi4UBAwbYP0+ZMgWLxcKpU6eeeG22bNlo3rx5jLbnefqKxG9r167FYrGwdu1aVzdFRCTOU9ItIhJPWCyWaH3pf4Jdr2PHjlgsFo4dO/bIcz799FMsFgt79uyJxZY9vfPnzzNgwAB27drl6qbYRf7iY+TIka5uSrScOXOGNm3akC1bNpIkSULatGmpXbs2GzZscHXTomjevHm0/o6J6V/eiIgkdB6uboCIiETP9OnTo3yeNm0aK1eufCCeN2/e53rOpEmTsFqtz3Rtnz596Nmz53M9PyFo3LgxY8aMYebMmfTr1++h5/z8888UKFCAggULPvNz3nvvPRo0aECSJEme+R5Pcv78eQYOHEi2bNkoXLhwlGPP01deFBs2bKB69eoAfPDBBwQEBHDx4kWmTJlCuXLl+Prrr+nQoYOLW2l8+OGHBAYG2j+fPHmSfv360bp1a8qVK2eP+/n5UapUKe7evUvixIld0VQRkXhFSbeISDzRpEmTKJ///vtvVq5c+UD8v+7cuYOXl1e0n5MoUaJnah+Ah4cHHh76T0upUqXImTMnP//880OT7k2bNnHy5EmGDx/+XM9xd3fH3d39ue7xPJ6nr7wIbty4wbvvvkvSpEnZsGEDfn5+9mNdunShSpUqdO7cmWLFilGmTJlYa1doaCiJEyfGzS3qhMfSpUtTunRp++dt27bRr18/Spcu/dC/Zzw9PZ3eVhGRhEDTy0VEEpCKFSuSP39+tm/fTvny5fHy8qJ3794ALFq0iBo1apAxY0aSJEmCn58fgwcPJiIiIso9/rtO999Teb/77jv8/PxIkiQJJUqUYOvWrVGufdiabovFQvv27Vm4cCH58+cnSZIk5MuXj2XLlj3Q/rVr11K8eHE8PT3x8/Nj4sSJ0V4nvm7dOurWrUuWLFlIkiQJmTNn5uOPP+bu3bsPvJ+3tzfnzp2jdu3aeHt74+vrS7du3R74XgQFBdG8eXN8fHxImTIlzZo1Iygo6IltATPafejQIXbs2PHAsZkzZ2KxWGjYsCH37t2jX79+FCtWDB8fH5IlS0a5cuVYs2bNE5/xsDXdNpuNIUOG8PLLL+Pl5UWlSpXYv3//A9dev36dbt26UaBAAby9vUmRIgXVqlVj9+7d9nPWrl1LiRIlAGjRooV9enHkevaHrem+ffs2Xbt2JXPmzCRJkgR/f39GjhyJzWaLct7T9ItndfnyZVq2bEm6dOnw9PSkUKFCTJ069YHzZs2aRbFixUiePDkpUqSgQIECfP311/bj9+/fZ+DAgeTKlQtPT09Sp05N2bJlWbly5WOfP3HiRC5evMiIESOiJNwASZMmZerUqVgsFgYNGgSYJNdisTy0jcuXL8disfDbb7/ZY+fOneP9998nXbp09u/fjz/+GOW6yLXXs2bNok+fPmTKlAkvLy+Cg4Of/A18jIet6Y78+2fPnj1UqFABLy8vcubMybx58wD4888/KVWqFEmTJsXf359Vq1Y9cN/ovJOISHyj4QgRkQTm2rVrVKtWjQYNGtCkSRPSpUsHmATN29ubLl264O3tzR9//EG/fv0IDg5mxIgRT7zvzJkzuXXrFh9++CEWi4UvvviCt99+mxMnTjxxxHP9+vUsWLCAjz76iOTJk/PNN9/wzjvvcObMGVKnTg3Azp07qVq1KhkyZGDgwIFEREQwaNAgfH19o/Xec+fO5c6dO7Rt25bUqVOzZcsWxowZwz///MPcuXOjnBsREUGVKlUoVaoUI0eOZNWqVXz55Zf4+fnRtm1bwCSvtWrVYv369bRp04a8efPyyy+/0KxZs2i1p3HjxgwcOJCZM2dStGjRKM+eM2cO5cqVI0uWLFy9epXvv/+ehg0b0qpVK27dusUPP/xAlSpV2LJlywNTup+kX79+DBkyhOrVq1O9enV27NjBG2+8wb1796Kcd+LECRYuXEjdunXJnj07ly5dYuLEiVSoUIEDBw6QMWNG8ubNy6BBgx6YYvyoUVmbzcZbb73FmjVraNmyJYULF2b58uV0796dc+fO8dVXX0U5Pzr94lndvXuXihUrcuzYMdq3b0/27NmZO3cuzZs3JygoiE6dOgGwcuVKGjZsyOuvv87nn38OwMGDB9mwYYP9nAEDBjBs2DA++OADSpYsSXBwMNu2bWPHjh1Urlz5kW349ddf8fT0pF69eg89nj17dsqWLcsff/zB3bt3KV68ODly5GDOnDkP9LPZs2eTKlUqqlSpAsClS5d45ZVX7L+88PX1ZenSpbRs2ZLg4GA6d+4c5frBgweTOHFiunXrRlhYmNOmhd+4cYM333yTBg0aULduXcaPH0+DBg346aef6Ny5M23atKFRo0aMGDGCd999l7Nnz5I8efJneicRkXjDJiIi8VK7du1s//1rvEKFCjbANmHChAfOv3PnzgOxDz/80Obl5WULDQ21x5o1a2bLmjWr/fPJkydtgC116tS269ev2+OLFi2yAbZff/3VHuvfv/8DbQJsiRMnth07dswe2717tw2wjRkzxh6rWbOmzcvLy3bu3Dl77OjRozYPD48H7vkwD3u/YcOG2SwWi+306dNR3g+wDRo0KMq5RYoUsRUrVsz+eeHChTbA9sUXX9hj4eHhtnLlytkA2+TJk5/YphIlSthefvllW0REhD22bNkyG2CbOHGi/Z5hYWFRrrtx44YtXbp0tvfffz9KHLD179/f/nny5Mk2wHby5EmbzWazXb582ZY4cWJbjRo1bFar1X5e7969bYCtWbNm9lhoaGiUdtls5medJEmSKN+brVu3PvJ9/9tXIr9nQ4YMiXLeu+++a7NYLFH6QHT7xcNE9skRI0Y88pzRo0fbANuMGTPssXv37tlKly5t8/b2tgUHB9tsNputU6dOthQpUtjCw8Mfea9ChQrZatSo8dg2PUzKlClthQoVeuw5HTt2tAG2PXv22Gw2m61Xr162RIkSRfmzFhYWZkuZMmWU/tCyZUtbhgwZbFevXo1yvwYNGth8fHzsfx7WrFljA2w5cuR46J+Rx3nczz7yvmvWrLHHIv/+mTlzpj126NAhG2Bzc3Oz/f333/b48uXLH7h3dN9JRCS+0fRyEZEEJkmSJLRo0eKBeNKkSe3/fuvWLa5evUq5cuW4c+cOhw4deuJ969evT6pUqeyfI0c9T5w48cRrAwMDo0yvLViwIClSpLBfGxERwapVq6hduzYZM2a0n5czZ06qVav2xPtD1Pe7ffs2V69epUyZMthsNnbu3PnA+W3atInyuVy5clHeZcmSJXh4eNhHvsGsoX6aoldNmjThn3/+4a+//rLHZs6cSeLEialbt679npGjjlarlevXrxMeHk7x4sUfOjX9cVatWsW9e/fo0KFDlCn5DxshTJIkiX1Nb0REBNeuXcPb2xt/f/+nfm6kJUuW4O7uTseOHaPEu3btis1mY+nSpVHiT+oXz2PJkiWkT5+ehg0b2mOJEiWiY8eOhISE8OeffwKQMmVKbt++/dip4ilTpmT//v0cPXr0qdpw69Yt+yjuo0Qej5zuXb9+fe7fv8+CBQvs56xYsYKgoCDq168PmBkF8+fPp2bNmthsNq5evWr/qlKlCjdv3nzgZ9isWbMof0acxdvbmwYNGtg/+/v7kzJlSvLmzUupUqXs8ch/j/xZP8s7iYjEF0q6RUQSmEyZMj106uj+/fupU6cOPj4+pEiRAl9fX3txpJs3bz7xvlmyZInyOTIBv3HjxlNfG3l95LWXL1/m7t275MyZ84HzHhZ7mDNnztC8eXNeeukl+zrtChUqAA++n6en5wPT1v/dHoDTp0+TIUMGvL29o5zn7+8frfYANGjQAHd3d2bOnAmYAla//PIL1apVi/ILjKlTp1KwYEH7emFfX19+//33aP1c/u306dMA5MqVK0rc19c3yvPAJPhfffUVuXLlIkmSJKRJkwZfX1/27Nnz1M/99/MzZsz4QKIZWVE/sn2RntQvnsfp06fJlSvXA8XC/tuWjz76iNy5c1OtWjVefvll3n///QfWlQ8aNIigoCBy585NgQIF6N69e7S2ekuePDm3bt167DmRxyO/Z4UKFSJPnjzMnj3bfs7s2bNJkyYNr732GgBXrlwhKCiI7777Dl9f3yhfkb9wu3z5cpTnZM+e/YntjQkvv/zyAzUYfHx8yJw58wMxcPz98SzvJCISX2hNt4hIAvOw0aygoCAqVKhAihQpGDRoEH5+fnh6erJjxw569OgRrW2fHlUl2/afAlkxfW10REREULlyZa5fv06PHj3IkycPyZIl49y5czRv3vyB94utit9p06alcuXKzJ8/n3HjxvHrr79y69YtGjdubD9nxowZNG/enNq1a9O9e3fSpk2Lu7s7w4YN4/jx405r29ChQ+nbty/vv/8+gwcP5qWXXsLNzY3OnTvH2jZgzu4X0ZE2bVp27drF8uXLWbp0KUuXLmXy5Mk0bdrUXtCsfPnyHD9+nEWLFrFixQq+//57vvrqKyZMmMAHH3zwyHvnzZuXnTt3EhYW9sht3fbs2UOiRImi/KKkfv36fPbZZ1y9epXkyZOzePFiGjZsaN8ZIPLn06RJk0fWGPjvVnSxMcoNj/6ZPuln/SzvJCISXyjpFhF5Aaxdu5Zr166xYMECypcvb4+fPHnSha1ySJs2LZ6enhw7duyBYw+L/dfevXs5cuQIU6dOpWnTpvb4k6pLP07WrFlZvXo1ISEhUUa7Dx8+/FT3ady4McuWLWPp0qXMnDmTFClSULNmTfvxefPmkSNHDhYsWBBlhLB///7P1GaAo0ePkiNHDnv8ypUrD4wez5s3j0qVKvHDDz9EiQcFBZEmTRr75+hUjv/381etWvXAtOrI5QuR7YsNWbNmZc+ePVit1iij3Q9rS+LEialZsyY1a9bEarXy0UcfMXHiRPr27WufafHSSy/RokULWrRoQUhICOXLl2fAgAGPTbrffPNNNm3axNy5cx+65dapU6dYt24dgYGBUZLi+vXrM3DgQObPn0+6dOkIDg6OMmXb19eX5MmTExEREWVf7fgsIb6TiEgkTS8XEXkBRI4y/XsE8d69e3z77beualIU7u7uBAYGsnDhQs6fP2+PHzt27IF1wI+6HqK+n81mi7Lt09OqXr064eHhjB8/3h6LiIhgzJgxT3Wf2rVr4+XlxbfffsvSpUt5++23o+xv/LC2b968mU2bNj11mwMDA0mUKBFjxoyJcr/Ro0c/cK67u/sDI8pz587l3LlzUWLJkiUDiNZWadWrVyciIoKxY8dGiX/11VdYLJZor8+PCdWrV+fixYtRpmmHh4czZswYvL297UsPrl27FuU6Nzc3+4hqWFjYQ8/x9vYmZ86c9uOP8uGHH5I2bVq6d+/+wDr10NBQWrRogc1me2Av97x581KgQAFmz57N7NmzyZAhQ5Rflrm7u/POO+8wf/589u3b98Bzr1y58th2xUUJ8Z1ERCJppFtE5AVQpkwZUqVKRbNmzejYsSMWi4Xp06fH6jTeJxkwYAArVqzg1VdfpW3btvbkLX/+/Ozateux1+bJkwc/Pz+6devGuXPnSJEiBfPnz3+utcE1a9bk1VdfpWfPnpw6dYqAgAAWLFjw1Oudvb29qV27tn1d97+nloMZDV2wYAF16tShRo0anDx5kgkTJhAQEEBISMhTPStyv/Fhw4bx5ptvUr16dXbu3MnSpUujjF5HPnfQoEG0aNGCMmXKsHfvXn766acoI+QAfn5+pEyZkgkTJpA8eXKSJUtGqVKlHrpGuGbNmlSqVIlPP/2UU6dOUahQIVasWMGiRYvo3LnzA3tVP6/Vq1cTGhr6QLx27dq0bt2aiRMn0rx5c7Zv3062bNmYN28eGzZsYPTo0faR+A8++IDr16/z2muv8fLLL3P69GnGjBlD4cKF7eu/AwICqFixIsWKFeOll15i27ZtzJs3j/bt2z+2falTp2bevHnUqFGDokWL8sEHHxAQEMDFixeZMmUKx44d4+uvv37oFmz169enX79+eHp60rJlywfWpg8fPpw1a9ZQqlQpWrVqRUBAANevX2fHjh2sWrWK69evP+u31WUS4juJiICSbhGRF0Lq1Kn57bff6Nq1K3369CFVqlQ0adKE119/3b7vr6sVK1aMpUuX0q1bN/r27UvmzJkZNGgQBw8efGJ19USJEvHrr7/SsWNHhg0bhqenJ3Xq1KF9+/YUKlTomdrj5ubG4sWL6dy5MzNmzMBisfDWW2/x5ZdfUqRIkae6V+PGjZk5cyYZMmSwF8OK1Lx5cy5evMjEiRNZvnw5AQEBzJgxg7lz57J27dqnbveQIUPw9PRkwoQJ9gRmxYoV1KhRI8p5vXv35vbt28ycOZPZs2dTtGhRfv/9d3r27BnlvESJEjF16lR69epFmzZtCA8PZ/LkyQ9NuiO/Z/369WP27NlMnjyZbNmyMWLECLp27frU7/Iky5Yte6DoGUC2bNnInz8/a9eupWfPnkydOpXg4GD8/f2ZPHkyzZs3t5/bpEkTvvvuO7799luCgoJInz499evXZ8CAAfZEt2PHjixevJgVK1YQFhZG1qxZGTJkCN27d39iG8uVK8eePXsYOnQoc+fO5cKFC/j4+FCmTBl+/PFHypYt+9Dr6tevT58+fbhz5469avm/pUuXji1btjBo0CAWLFjAt99+S+rUqcmXL599v/H4JiG+k4gIgMUWl4Y5RERE/qN27drPtF2TiIiISFygNd0iIhJn3L17N8rno0ePsmTJEipWrOiaBomIiIg8J410i4hInJEhQwaaN29Ojhw5OH36NOPHjycsLIydO3c+sPe0iIiISHygNd0iIhJnVK1alZ9//pmLFy+SJEkSSpcuzdChQ5Vwi4iISLylkW4RERERERERJ9GabhEREREREREnUdItIiIiIiIi4iRa0/0QVquV8+fPkzx5ciwWi6ubIyIiIiIiInGMzWbj1q1bZMyYETe3R49nK+l+iPPnz5M5c2ZXN0NERERERETiuLNnz/Lyyy8/8riS7odInjw5YL55KVKkcHFrJCZYrVauXLmCr6/vY38LJfI01K/EGdSvxFnUt8QZ1K/EWeJD3woODiZz5sz2/PFRlHQ/ROSU8hQpUijpTiCsViuhoaGkSJEizv6hlfhH/UqcQf1KnEV9S5xB/UqcJT71rSctSY7brRcRERERERGJx5R0i4iIiIiIiDiJkm4RERERERERJ9GabhERERERidesViv37t1zdTMkBlmtVu7fv09oaKjL1nQnSpQId3f3576Pkm4REREREYm37t27x8mTJ7Fara5uisQgm82G1Wrl1q1bTyxU5kwpU6Ykffr0z9UGJd0iIiIiIhIv2Ww2Lly4gLu7O5kzZ47zVa4l+mw2G+Hh4Xh4eLgk6bbZbNy5c4fLly8DkCFDhme+l5JuERERERGJl8LDw7lz5w4ZM2bEy8vL1c2RGOTqpBsgadKkAFy+fJm0adM+81Rz/SpIRERERETipYiICAASJ07s4pZIQhX5y5z79+8/8z2UdIuIiIiISLzmyjW/krDFRN9S0i0iIiIiIiLiJEq6RURERERE4rls2bIxevToaJ+/du1aLBYLQUFBTmuTGEq6RUREREREYonFYnns14ABA57pvlu3bqV169bRPr9MmTJcuHABHx+fZ3pedCm5d3HSPWDAgAc6WZ48eR57zdy5c8mTJw+enp4UKFCAJUuWRDlus9no168fGTJkIGnSpAQGBnL06FFnvoaIiIiIiEi0XLhwwf41evRoUqRIESXWrVs3+7mRFbyjw9fX96kquCdOnPi595+W6HH5SHe+fPmidLL169c/8tyNGzfSsGFDWrZsyc6dO6lduza1a9dm37599nO++OILvvnmGyZMmMDmzZtJliwZVapUITQ0NDZeR0RERERE5JHSp09v//Lx8cFisdg/Hzp0iOTJk7N06VKKFStGkiRJWL9+PcePH6dWrVqkS5cOb29vSpQowapVq6Lc97/Tyy0WC99//z116tTBy8uLXLlysXjxYvvx/45AT5kyhZQpU7J8+XLy5s2Lt7c3VatW5cKFC/ZrwsPD6dixIylTpiR16tT06NGDZs2aUbt27Wf+fty4cYOmTZuSKlUqvLy8qFatWpRB09OnT1OzZk1SpUpFsmTJyJcvn33g9caNGzRu3BhfX1+SJk1Krly5mDx58jO3xVlcnnR7eHhE6Xhp0qR55Llff/01VatWpXv37uTNm5fBgwdTtGhRxo4dC5jfBI0ePZo+ffpQq1YtChYsyLRp0zh//jwLFy6MpTcSERERERF5dj179mT48OEcPHiQggULEhISQvXq1Vm9ejU7d+6katWq1KxZkzNnzjz2PgMHDqRevXrs2bOH6tWr07hxY65fv/7I8+/cucPIkSOZPn06f/31F2fOnIky8v7555/z008/MXnyZDZs2EBwcPBz51nNmzdn27ZtLF68mE2bNmGz2ahevbp9i6727dsTFhbGX3/9xd69e/n888/x9vYGoG/fvhw4cIClS5dy8OBBxo8f/9h80lU8XN2Ao0ePkjFjRjw9PSldujTDhg0jS5YsDz1306ZNdOnSJUqsSpUq9h/0yZMnuXjxIoGBgfbjPj4+lCpVik2bNtGgQYOH3jcsLIywsDD75+DgYACsVitWq/V5Xk/iCKvVis1m089TYpT6lTiD+pU4i/qWOIOr+1Xk8yO/AEqUgIsXY78t6dPD1q1Pd01km//7z4EDB0bJaVKlSkXBggXtnwcNGsQvv/zCokWLaN++fZT7Rd4DoFmzZvYc6LPPPuObb75h8+bNVK1aNcozI7/u37/P+PHj8fPzA6Bdu3YMHjzYfu6YMWPo2bOnfWR7zJgx9lHnfz/3Ue/433OOHj3K4sWLWb9+PWXKlAFgxowZZMmShYULF1K7dm3OnDnD22+/Tf78+QHInj27/X5nzpyhcOHCFCtWDICsWbM+ti3PIrLdD8sNo9vvXZp0lypViilTpuDv78+FCxcYOHAg5cqVY9++fSRPnvyB8y9evEi6dOmixNKlS8fF//+pivzn4855mGHDhjFw4MAH4leuXNG09ATCarVy8+ZNbDYbbm4un+AhCYT6lTiD+pU4i/qWOIOr+9X9+/exWq2Eh4fb1z5fvOjBuXOuWKcc/fXXkSKTtsjrIiIiAChcuHCUe4WEhDB48GCWLFnCxYsXCQ8P5+7du5w6dSrKeZHfi0j58uWzf06SJIl9/Xh4eLj9WZHfO6vVipeXF1mzZrVfkzZtWi5fvkx4eDg3b97k0qVLFCtWLMozihQp8sBz/+2/z/m3ffv24eHhEeWePj4+5M6dm/3791OzZk0++ugjOnTowIoVK3jttdeoU6eO/RcQrVq1on79+uzYsYPAwEBq1apF6dKln+pn8CSR35tr166RKFGiKMdu3boVrXu4NOmuVq2a/d8LFixIqVKlyJo1K3PmzKFly5ax1o5evXpFGUEPDg4mc+bM+Pr6kiJFilhrhziP1WrFYrHg6+ur/9GQGKN+Jc6gfiXOor4lzuDqfhUaGsqtW7fw8PDAw8OkNunTA8TcSGd0pU+PvQ3RFfk9i7zO3d0dMInnv+/Vs2dPVq1axYgRI8iZMydJkyalbt26hIeHRznPzc0tymdPT88onyOLV3t4eNifFfm9c3NzI1GiRFHO9/DwwGazRfn+uru7P/DMf7/Df/33OY86Fvnvke10c3PD3d2dDz/8kOrVq/P777+zcuVKvvjiC0aOHEmHDh148803OXXqFEuWLGHVqlVUqVKFjz76iJEjRz7mu/50Ir83qVOnxtPTM8qx/35+5D1irDUxIGXKlOTOnZtjx4499Hj69Om5dOlSlNilS5dIb/5k2f956dIlMmTIEOWcwoULP/K5SZIkIUmSJA/E3dzc4ux/lPbtg+PHoVYtV7ck/oj8wxtXf6YSP6lfiTOoX4mzqG+JM7iyX7m5uUXZCQlg27ZYb8Yzi2zzw/7576riGzdupHnz5rz99tuAGfk+deoUFStWjHLef6/77+d/x/77rP+24b/tSZkyJenSpWPbtm1UqFABMKPYO3bsoHDhwo+sgv6odwIICAggPDycLVu22KeXX7t2jcOHDxMQEGA/P0uWLLRt25a2bdvSq1cvvv/+ezp27AiY0fjmzZvTvHlzypUrR/fu3fnyyy8f+T1/WpHtflgfj26fj1N/44aEhHD8+PEoCfO/lS5dmtWrV0eJrVy50j6FIHv27KRPnz7KOcHBwWzevDnGpxm4ktUKrVtD7drm6wn1E0REREREJB7LlSsXCxYsYNeuXezevZtGjRq5ZB19hw4dGDZsGIsWLeLw4cN06tSJGzduRGvbsb1797Jr1y771+7du8mVKxe1atWiVatWrF+/nt27d9OkSRMyZcpErf+PLnbu3Jnly5dz8uRJduzYwZo1a8ibNy8A/fr1Y9GiRRw7doz9+/fz22+/2Y/FJS4d6e7WrRs1a9Yka9asnD9/nv79++Pu7k7Dhg0BaNq0KZkyZWLYsGEAdOrUiQoVKvDll19So0YNZs2axbZt2/juu+8A81uIzp07M2TIEHLlykX27Nnp27cvGTNmfK4y9nHN77/Dpk3m3xctglWrYOBA6NQJnnJGi4iIiIiIxHGjRo3i/fffp0yZMqRJk4YePXrYiz/Hph49enDx4kWaNm2Ku7s7rVu3pkqVKlGmhj9K+fLlo3x2d3cnPDycyZMn06lTJ958803u3btH+fLlWbJkCYkSJbKvPW/Xrh3//PMPKVKkoGrVqnz11VeA2Wu8V69enDp1iqRJk1KuXDlmzZrllHd/HhZbTJZ2e0oNGjTgr7/+4tq1a/j6+lK2bFk+++wze7W8ihUrki1bNqZMmWK/Zu7cufTp04dTp06RK1cuvvjiC6pXr24/brPZ6N+/P9999x1BQUGULVuWb7/9lty5c0e7XcHBwfj4+HDz5s04uabbZoPZs6FzZ/j3bPtChWDCBHjlFZc1Lc6yWq1cvnyZtGnTakqdxBj1K3EG9StxFvUtcQZX96vQ0FBOnjxJ9uzZo72+VmKO1Wolb9681KtXj8GDB8fovW02m33NenRG0p3lcX0sunmjS5PuuCquJ92RgoLg009h/HiTiANYLPDhhzBsGKRM6crWxS2u/g+CJEzqV+IM6lfiLOpb4gyu7ldKumPX6dOnWbFiBRUqVCAsLIyxY8cyefJkdu/eHePTuhNS0q2/ceOxlClh3Dgz1TyyTpzNZka78+SBn392JOMiIiIiIiLPw83NjSlTplCiRAleffVV9u7dy6pVq+LkOuq4REl3AlCqFGzdCqNGQbJkJnbpEjRqBFWqwCOKwYuIiIiIiERb5syZ2bBhAzdv3iQ4OJiNGzc+sFZbHqSkO4Hw8ICPP4aDB01F80grV0L+/DB4MISFuax5IiIiIiIiLyQl3QlM5szwyy+mqnmWLCYWFgb9+plCa2vXurR5IiIiIiIiLxQl3QnUW2/B/v3QrRtEVvA/fBgqVYJmzeDKFde2T0RERERE5EWgpDsB8/aGESNgx46o24hNm2YKrf3wA1itrmufiIiIiIhIQqek+wVQsCBs2GCqmkduI3b9OnzwAVSoYEbERUREREREJOYp6X5BuLmZ/bsPHYLGjR3x9evNdmO9esGdOy5rnoiIiIiISIKkpPsFky4dzJhhqprnymVi4eEwfDjkywdLlri2fSIiIiIi8mQVK1akc+fO9s/ZsmVj9OjRj73GYrGwcOHC5352TN3nRaGk+wUVGAh79kD//pA4sYmdOgU1akDdunD+vEubJyIiIiKSINWsWZOqVas+9Ni6deuwWCzs2bPnqe+7detWWrdu/bzNi2LAgAEULlz4gfiFCxeoVq1ajD7rv6ZMmYKvr69TnxFblHS/wDw9YcAAk3y/9pojPm+eKbQ2ZgxERLiseSIiIiIiCU7Lli1ZuXIl//zzzwPHJk+eTPHixSlYsOBT39fX1xcvL6+YaOITpU+fniRJksTKsxICJd2Cvz+sWmWqmkf+MunWLejYEUqVgu3bXds+EREREZGE4s0338TX15cpU6ZEiYeEhDB37lxatmzJtWvXaNiwIZkyZcLLy4sCBQrw888/P/a+/51efvToUcqXL4+npycBAQGsXLnygWt69OhB7ty58fLyIkeOHPTt25f79+8DZqR54MCB7N69G4vFgsVisbf5v9PL9+7dy2uvvUbSpElJnTo1rVu3JiQkxH68efPm1K5dm5EjR5IhQwZSp05Nu3bt7M96FmfOnKFWrVp4e3uTIkUK6tWrx6VLl+zHd+/eTaVKlUiePDkpUqSgWLFibNu2DYDTp09Ts2ZNUqVKRbJkyciXLx9LnLjOVkm3AGCxwHvvmUJrrVo54tu3Q8mS0KkTBAe7rn0iIiIiIgmBh4cHTZs2ZcqUKdhsNnt87ty5RERE0LBhQ0JDQylWrBi///47+/bto3Xr1rz33nts2bIlWs+wWq28/fbbJE6cmM2bNzNhwgR69OjxwHnJkydnypQpHDhwgK+//ppJkybx1VdfAVC/fn26du1Kvnz5uHDhAhcuXKB+/foP3OP27dtUqVKFVKlSsXXrVubOncuqVato3759lPPWrFnD8ePHWbNmDVOnTmXKlCkP/OIhuqxWK7Vq1eL69ev8+eefrFy5khMnTkRpX+PGjXn55ZfZunUr27dvp2fPniRKlAiAdu3aERYWxl9//cXevXv5/PPP8fb2fqa2RIeH0+4s8dJLL8F330GzZtCmDezbZ/by/uYbM+3866/hnXdMki4iIiIiEucULw4XL8b+c9Onh/+PpD7J+++/z4gRI/jzzz+pWLEiYKaWv/POO/j4+ODj40O3bt3s53fo0IHly5czZ84cSpYs+cT7r1q1ikOHDrF8+XIyZswIwNChQx9Yh92nTx/7v2fLlo1u3boxa9YsPvnkE5ImTYq3tzceHh6kT5/+kc+aOXMmoaGhTJs2jWTJkgEwduxYatasyeeff066dOkASJUqFWPHjsXd3Z08efJQo0YNVq9eTat/j/hF0+rVq9m7dy8nT54kc+bMAEybNo18+fKxdetWSpQowZkzZ+jevTt58uQBIFdkFWnMKPk777xDgQIFAMiRI8dTt+FpKOmWh3r1VdixA776yqz7vnvXFFerWxeqV4exYyF7dle3UkRERETkPy5ehHPnXN2Kx8qTJw9lypThxx9/pGLFihw7dox169YxaNAgACIiIhg6dChz5szh3Llz3Lt3j7CwsGiv2T548CCZM2e2J9wApUuXfuC82bNn880333D8+HFCQkIIDw8nRYoUT/UuBw8epFChQvaEG+DVV1/FarVy+PBhe9KdL18+3N3d7edkyJCBvXv3PtWz/v3MzJkz2xNugICAAFKmTMnBgwcpUaIEXbp04YMPPmD69OkEBgZSt25d/Pz8AOjYsSNt27ZlxYoVBAYG8s477zzTOvro0vRyeaREieCTT+DAAVPVPNKSJWZ7seHD4TmWYYiIiIiIxLz06SFTptj/esxo8MO0bNmS+fPnc+vWLSZPnoyfnx8VKlQAYMSIEXz99df06NGDNWvWsGvXLqpUqcK9e/di7Nu0adMmGjduTPXq1fntt9/YuXMnn376aYw+498ip3ZHslgsWK1WpzwLTOX1/fv3U6NGDf744w8CAgL45ZdfAPjggw84ceIE7733Hnv37qV48eKMGTPGaW3RSLc8UbZs8Ouv8MsvprjauXNm5LtXL7Pn94QJULasq1spIiIiIkK0p3i7Wr169ejUqRMzZ85k2rRptG3bFsv/13Bu2LCBWrVq0aRJE8CsYT5y5AgBAQHRunfevHk5e/YsFy5cIEOGDAD8/fffUc7ZuHEjWbNm5dNPP7XHTp8+HeWcxIkTE/GE7Yzy5s3LlClTuH37tn20e8OGDbi5ueHv7x+t9j6tyPc7e/asfbT7wIEDBAUFRfke5c6dm9y5c/Pxxx/TsGFDJk+eTJ06dQDInDkzbdq0oU2bNvTq1YtJkybRoUMHp7RXI90SLRYLvP02HDxoiqq5/b/n7N8P5crBBx/AtWuubaOIiIiISHzh7e1N/fr16dWrFxcuXKB58+b2Y7ly5WLlypVs3LiRgwcP8uGHH0apzP0kgYGB5M6dm2bNmrF7927WrVsXJbmOfMaZM2eYNWsWx48f55tvvrGPBEfKli0bJ0+eZNeuXVy9epWwsLAHntW4cWM8PT1p1qwZ+/btY82aNXTo0IH33nvPPrX8WUVERLBr164oXwcPHiQwMJACBQrQuHFjduzYwZYtW2jatCkVKlSgePHi3L17l/bt27N27VpOnz7Nhg0b2Lp1K3nz5gWgc+fOLF++nJMnT7Jjxw7WrFljP+YMSrrlqSRPDqNHw9atpkZFpB9+MHt7T5sG/yrCKCIiIiIij9CyZUtu3LhBlSpVoqy/7tOnD0WLFqVKlSpUrFiR9OnTU7t27Wjf183NjV9++YW7d+9SsmRJPvjgAz777LMo57z11lt8/PHHtG/fnsKFC7Nx40b69u0b5Zx33nmHqlWrUqlSJXx9fR+6bZmXlxfLly/n+vXrlChRgnfffZfXX3+dsWPHPt034yFCQkIoWrQoRYoUsX/VrFkTi8XCokWLSJUqFeXLlycwMJAcOXIwe/ZsANzd3bl27RpNmzYld+7c1KtXj2rVqjFw4EDAJPPt2rUjb968VK1aldy5c/Ptt98+d3sfxWKzKUX6r+DgYHx8fLh58+ZTFxJ4kUREwPjx0Lu32dc7UsWKJv7/QoFxgtVq5fLly6RNmxY3N/2uSWKG+pU4g/qVOIv6ljiDq/tVaGgoJ0+eJHv27Hh6esb688V5bDYb4eHheHh42Kfdu8Lj+lh080b9jSvPzN0d2rc3e3vXq+eIr10LhQpBv34QGuqy5omIiIiIiLicku746vp1CAlxdSsAyJgRZs+GpUsd24jduweDB0OBArBypWvbJyIiIiIi4ipKuuOrnj0hVy6YNAnCw13dGgCqVoV9+8x088gdAY4dgzfegEaNzJaJIiIiIiIiLxIl3fHR/v2mctnFi9C6tZnL/fvvcaKCmZcXfPYZ7NplqppH+vlns8Z7wgRw4nZ8IiIiIiIicYqS7vjIywtq1XJ8PnAA3nwTXn8dtm93Xbv+JSAA/vwTfvwRUqc2sZs3oW1bKFMGdu92bftERERERERig5Lu+Ch7dliwANatg1deccTXrDH7eDVpAqdOuax5kSwWaNHCFFr717aDbN4MxYpBt25xZlm6iIiIiMRj2pBJnMUaA9N0PWKgHeIqZcvCxo0wbx706gXHj5v4Tz/B3LnQsaNZYJ0qlUubmSYNTJ5sEu82bUwSHhEBX34Jc+bAmDFRB+5FRERERKIjUaJEWCwWrly5gq+vr0u3lpKY5eotw2w2G/fu3ePKlSu4ubmROHHiZ76X9ul+iHi5T/e9e2Zz7EGDTGXzSC+9BH36wEcfQZIkrmvf/4WFwciRMGRI1O3EatWCb76BLFmc81xX7yEpCZP6lTiD+pU4i/qWOENc6FchISH8888/Gu1OYGw2G1arFTc3N5f+MsXLy4sMGTI8NOmObt6opPsh4mXSHSkoCIYNg6+/NhlupOzZYfhwqFvXzPt2sePHze8BVqxwxJIlg4EDoVMn8IjhORhx4T8IkvCoX4kzqF+Js6hviTPElX4VERHB/fv3XfZ8iXlWq5Vr166ROnVql/Utd3f3x460K+l+DvE66Y505owZ4Z4+PWq8VCkz1Fy2rGva9S82m5le3rlz1O3EChWCiRNNU2NKXPkPgiQs6lfiDOpX4izqW+IM6lfiLPGhb0U3b4ybrZfnlyULTJsGO3aYquaRNm82e3nVqQOHD7uufZgB9/r14eBBM+od+Quk3buhdGkTCwpyaRNFRERERESei5LuhK5IEVi5EpYsgfz5HfGFCyFfPpPZXr7ssuYBpEwJ48bB339D4cImZrOZJep58pg9vjUfQ0RERERE4iMl3S8CiwWqVYNdu+D77yFDBhOPiDCZrZ+fqWx2545Lm1myJGzdCqNGmfXdAJcuQaNGUKUKHDvm0uaJiIiIiIg8NSXdLxJ3d2jZEo4eNVXOvb1NPCQE+vaFXLngxx9NMu4iHh7w8cdmynmdOo74ypVmoH7w4Kj14UREREREROIyJd0vomTJTJJ97JjZONvd3cTPnzdJeZEisGyZS+d0Z84MCxbA4sWObcTCwqBfP1Nobe1alzVNREREREQk2pR0v8jSpTPTy/ftg7fecsT37jXT0d94w0xJd6GaNeHAAeje3fG7gcOHoVIlaNYMrlxxafNEREREREQeS0m3mGplixbBn39CiRKO+KpVULSoyW7PnnVZ85Ilgy++MIXYS5d2xKdNM03/4QewWl3WPBERERERkUdS0i0O5cubEuI//wzZs5uYzWay29y5oVcvuHnTZc0rWBDWrzd7eKdMaWLXr8MHH0CFCrB/v8uaJiIiIiIi8lBKuiUqNzdo0MBUMvvyS0iVysRDQ2H4cMiZE8aMgXv3XNa81q3h0CFo0sQRX7/ebDfWq5fLi7CLiIiIiIjYKemWh0uSBLp0gePHoWtXSJzYxK9ehY4dzR7f8+e7rNhaunQwfbqpap4rl4mFh5vfC+TPD0uXuqRZIiIiIiIiUSjplsdLlQpGjjRDyw0bOuLHjsG770LZsrBxo8uaFxgIe/ZA//6O3wucPAnVq0PduqYgu4iIiIiIiKso6ZboyZ4dZs6ErVvNAupIGzfCq6+aBPzoUZc0zdMTBgwwyfdrrzni8+aZQmtjxrh063EREREREXmBKemWp1O8OKxZA7/+CnnzOuLz50NAgJl6fvWqS5rm728Krk+fDr6+JnbrlmlS6dIWdu/2cEm7RERERETkxaWkW56exQJvvmmGlidONAuswSyqHjMG/PzM4uq7d13StCZNzGz4Vq0c8e3bLVSrlpoOHSwEBcV6s0RERERE5AWlpFuenYeHKSV+7JhZVO3lZeLBwaaMeO7cMHWqSzbRfukl+O472LDBFFYDsNksfPutBX9/mDHDZTXgRERERETkBaKkW56ft7dZVH3smBledvt/t/rnH2jeHIoWNWXGXaBMGdixA774woqXl0n+L1+G996DSpXgwAGXNEtERERERF4QSrol5mTIYIaX9+yBGjUc8d274Y03oGpVcyyWJUpkdj3766+rvP22Y3j7zz+hUCEzKH/7dqw3S0REREREXgBKuiXm5csHv/0Gf/xhRrkjLV8OhQvD++/DuXOx3qxMmazMnWtjyRLIkcPEIvf2DgiARYs05VxERERERGKWkm5xnkqVzBZjM2ZAliwmZrPB5MmQKxf07WvKi8eyatVg376oe3ufOQO1a8Nbb5l9vkVERERERGKCkm5xLjc3aNwYDh+GL74AHx8Tv3sXhgwxlc6//Rbu34/VZiVNapah79tnZr5H+u03M1A/dCiEhcVqk0REREREJAFS0i2xw9MTuneH48ehc2ez0BrgyhVo1w4KFICFC2N9fneuXLBsGcyZAxkzmtjdu/Dpp2a99+rVsdocERERERFJYJR0S+xKnRq++goOHoR69Rzxw4ehTh2oUAE2b47VJlksULeu2du7Sxdwd3c0KTAQGjWCCxditUkiIiIiIpJAKOkW1/Dzg9mz4e+/oWxZR3zdOnjlFahfH06ciNUmJU8OX35pthgrU8YR//ln8PeHb74xhddERERERESiS0m3uFapUvDXX/DLL5A7tyM+Zw7kyQMffwzXrsVqkwoWNLn/Dz+YgXkw9d46dYISJczvCURERERERKJDSbe4nsViSofv2wfjxoGvr4nfvw+jR5tR8REjIDQ01prk5mZ2Njt8GFq1csR37YLSpaF161j/XYCIiIiIiMRDSrol7kiUCD76CI4dM5XMkiY18Zs34ZNPzMj3Tz+B1RprTUqdGr77DjZtMluMR5o0yTRn8uRYbY6IiIiIiMQzSrol7kmRwmwndvSoGW62WEz89Glo0sTM8V6zJlab9MorZsvxr782a78Brl41zStfHvbsidXmiIiIiIhIPKGkW+KuTJnMwurdu6FqVUd8xw547TV48004cCDWmuPhAR07mirnDRo44hs2QNGi0LWrWfstIiIiIiISSUm3xH0FCsDSpbByZdQ53r//bo61bh2re3plzGgqmq9c6aj9FhEBo0aZKedz58b6duMiIiIiIhJHKemW+CMwELZvh6lT4eWXTcxqNQusc+WCAQMgJCRWm7Nnj5kJ7+lpYufPm+3Hq1UzS9NFREREROTFpqRb4hc3N2jaFI4cgWHDzPpvgNu3YeBAk3x/912sbaidJImp+XbgANSo4YgvXw7585vfA8Ri0XUREREREYljlHRL/JQ0KfTsaYaTO3QwC64BLl6EDz80m23/9luszfPOnh1+/RUWLoQsWUwsLMz8HiB/fli2LFaaISIiIiIicUycSbqHDx+OxWKhc+fOjzzn/v37DBo0CD8/Pzw9PSlUqBDL/pPNDBgwAIvFEuUrT548Tm69uIyvL3zzjRlqfucdR/zgQahZ0xRc27YtVppisUCtWqYpPXs6fg9w/LiZbv7uu3D2bKw0RURERERE4og4kXRv3bqViRMnUrBgwcee16dPHyZOnMiYMWM4cOAAbdq0oU6dOuzcuTPKefny5ePChQv2r/Xr1zuz+RIX5MoF8+aZUuKlSzvia9dCiRJYGjfGPZYy3mTJzMz33buhQgVHfP58yJsXRo6E+/djpSkiIiIiIuJiLk+6Q0JCaNy4MZMmTSJVqlSPPXf69On07t2b6tWrkyNHDtq2bUv16tX58ssvo5zn4eFB+vTp7V9p0qRx5itIXFKmjEm8582DnDntYcusWaQpWxZLly5mg+1YEBBgthOfPh3SpjWx27ehe3ezxZh+FyQiIiIikvB5uLoB7dq1o0aNGgQGBjJkyJDHnhsWFoZnZJno/0uaNOkDI9lHjx4lY8aMeHp6Urp0aYYNG0aWyIW2j7hvWFiY/XNwcDAAVqsVq9X6tK8kcUGdOqay2XffYRk0CMu1a1ju3YOvv8Y2eTK2Tz6BTp3Ay8vpTWnUCKpXh759LYwfDzabhX37oFw5aNbMxuef2/D1dXozxAmsVis2m01/T0iMUr8SZ1HfEmdQvxJniQ99K7pts9hsrttReNasWXz22Wds3boVT09PKlasSOHChRk9evRDz2/UqBG7d+9m4cKF+Pn5sXr1amrVqkVERIQ9aV66dCkhISH4+/tz4cIFBg4cyLlz59i3bx/Jkyd/6H0HDBjAwIEDH4gfOXLkkddI/GEJDsZr7FiSTZqE279KiUekS0dIt27cbdDAsQDbyXbt8qBnTx92705kj6VMaaVXr1s0aXIXN5fPPZGnYbVauXnzJj4+PrjphycxRP1KnEV9S5xB/UqcJT70rVu3bpE7d25u3rxJishdlR7CZUn32bNnKV68OCtXrrSv5X5S0n3lyhVatWrFr7/+isViwc/Pj8DAQH788Ufu3r370GuCgoLImjUro0aNomXLlg8952Ej3ZkzZ+bGjRuP/eZJ/GG1Wrm2dy++48ZhmTwZy79+K2XLkwfbZ5+ZKmgWi9PbEhFhdjX79FMLN286nleypI1x42wULer0JkgMsVqtXLlyBV9f3zj7HwOJf9SvxFnUt8QZ1K/EWeJD3woODiZVqlRxN+leuHAhderUwd3d3R6LiIjAYrHg5uZGWFhYlGP/FhoayrVr18iYMSM9e/bkt99+Y//+/Y98VokSJQgMDGTYsGHRaltwcDA+Pj5P/OZJ/GG1Wrl8+TJp06bF7cgR6NXL7O/1b2XKwOefQ9mysdKmS5fgk09g2jRHzM0N2rWDwYPBxydWmiHPIUq/iqP/MZD4R/1KnEV9S5xB/UqcJT70rejmjS5r/euvv87evXvZtWuX/at48eI0btyYXbt2PTLhBvD09CRTpkyEh4czf/58atWq9chzQ0JCOH78OBkyZHDGa0h8lCcP/PKLKbj26quO+MaNZqF15L5fTpYuHUydagqsBwSYmNUKY8aAvz/MnBlr24yLiIiIiIiTuCzpTp48Ofnz54/ylSxZMlKnTk3+/PkBaNq0Kb169bJfs3nzZhYsWMCJEydYt24dVatWxWq18sknn9jP6datG3/++SenTp1i48aN9tH0hg0bxvo7ShxXpgysWweLFpm9vCItXgwFCsAHH8A//zi9GRUqwK5d8MUXjrpuly5B48bw+utw6JDTmyAiIiIiIk4SN8fp/+/MmTNcuHDB/jk0NJQ+ffoQEBBAnTp1yJQpE+vXrydlypT2c/755x8aNmyIv78/9erVI3Xq1Pz999/4qjy0PIzFAm+9BXv2wA8/QKZMJm61ms+5ckHPnhAU5NRmJEpkthI7eNAUXo+0Zg0ULAiffgp37ji1CSIiIiIi4gQurV4eV2lNd8IT7TUhd+6Y+d3DhsHNm454qlQm823XDv6zbZ0z/P47dOgAJ086YlmzmqbVrOn0x0s0xYe1RhL/qF+Js6hviTOoX4mzxIe+FefXdIvESV5e0KMHnDgBXbtC4sQmfuMGdOtmFltPm2ZKkDtRjRqwfz/07etowunTZlC+Vi04dcqpjxcRERERkRiipFvkYV56CUaOhCNHoGlTx1ZiZ85As2ZQpAgsXerUSmdJk8KgQbB3LwQGOuKLF5vCa8OGwb17Tnu8iIiIiIjEACXdIo+TNaspMb5rF1Sr5ojv3QvVq8Nrr8HWrU5tQu7csGIFzJoFkUX4796F3r2hUCH44w+nPl5ERERERJ6Dkm6R6ChYEJYsMRluiRKO+Nq1ULIk1KsHR4867fEWC9SvbyqZd+5s9vMG8/n116FJE7h40WmPFxERERGRZ6SkW+RpVKoEmzfDnDmQM6cjPneumfPdrp3Z78tJUqSAr76C7duhdGlH/KefzHLzsWOdvtxcRERERESegpJukadlsUDdunDgAHz7LaRLZ+Lh4eaznx/07w+3bjmtCYULw/r18P33Zvk5QHCwqXheogRs2eK0R4uIiIiIyFNQ0i3yrBIlgrZt4dgxGDgQvL1N/PZtUwHNz88MPTup2pmbG7RsCYcPm39G2rkTXnkF2rSB69ed8mgREREREYkmJd0iz8vbG/r1M8l3+/bg4WHiV66YoeeAAJg9G6xWpzw+TRoz4r1hg1l6Dqao+sSJZsr5lClOLbIuIiIiIiKPoaRbJKakSwdjxsDBg6bqWaTjx6FBA1NwzYmlxsuUMWu9v/rKMeh+9Sq0aAHly8O+fU57tIiIiIiIPIKSbpGYljOn2d9r61azpVik7dtNqfGqVWH3bqc82sPDVDc/dChq3r9+vVkH3r07hIQ45dEiIiIiIvIQSrpFnKV4cVi1CpYtMxtqR1q+HIoUgffeg1OnnPLoTJlM3r9iBeTKZWIRETByJOTNC/Pna8q5iIiIiEhsUNIt4kwWC1SpAjt2wPTpkDWridtsMGOGWXTdpYuZB+4ElSvD3r0weDB4eprYP//Au+9C9epmGbqIiIiIiDiPkm6R2ODmBk2amFLjo0Y59vm6d88swvbzg2HD4M6dGH90kiTQpw/s3w/Vqjniy5ZB/vym8HpoaIw/VkREREREUNItEruSJIGPP4YTJ6B3b0ia1MSDg83nXLlg0iSz53cMy5EDfv8dFiyAl182sbAwGDAAChQwU9FFRERERCRmKekWcQUfH/jsMzh6FFq1MiPhAOfPQ+vWJgteuDDGF15bLFCnjimw/sknjt3Njh0zs+Dr1YNz52L0kSIiIiIiLzQl3SKulCkTfPed2c+rdm1H/NAhkx2XLWs24I5h3t7w+eewa5fZTizS3LmQJ4+ZAX//fow/VkRERETkhaOkWyQuyJsXfvnFJNivvuqIb9xoEu9ateDAgRh/bL58sHYtTJ0Kvr4mFhICXbuaAutr18b4I0VEREREXihKukXikjJlYN06WLTIJOKRFi82U84/+MCUH49BFgs0bWpqvLVtaz6DKbxWqRI0amRmvYuIiIiIyNNT0i0S11gs8NZbsGcPfP89ZMxo4lYr/PCDKbbWqxcEBcXoY1Olgm+/hS1boGRJR/znn83OZl9+qSnnIiIiIiJPS0m3SFzl4QEtW5pia8OGmeJrYPb3Gj7cbDM2alSM7/dVvDhs2mSKqKdObWIhIdCtGxQuDGvWxOjjREREREQSNCXdInGdlxf07AnHj5vF1okTm/j16+azvz9MmwYRETH2SDc3M5P9yBFo08Yx5fzAAXjtNWjYUFXORURERESiQ0m3SHyROjWMHGky4aZNHZnwmTPQrBkULQpLl8boNmMvvQTjx8PWrVCqlCM+a5apcj5ypKaci4iIiIg8jpJukfgma1ZTbnznTqhWzRHfsweqVzdD0Vu3xugjixUzhdS//x7SpDGxkBDo3h0KFYI//ojRx4mIiIiIJBhKukXiq0KFYMkSk/GWKOGIr11rKqHVq2fWg8cQNzezxPzwYfjoI8dA+8GD8PrrUL9+jBdWFxERERGJ95R0i8R3lSrB5s0wZw7kzOmIz50LAQHQrh1cuhRjj3vpJRg3DrZtg1deccTnzDFTzr/4Au7di7HHiYiIiIjEa0q6RRICiwXq1jWVzsaNg7RpTTw83OwD5ucHAwbArVsx9siiRWHDBvjxR8eU89u3oUcPMwi/enWMPUpEREREJN5S0i2SkCRKZOZ+Hz9ukmxvbxO/fRsGDjQj4ePGxdhQtJsbtGhharu1a2c+Axw6BIGBZoa7ppyLiIiIyItMSbdIQuTtDf37w7FjJhv28DDxy5ehfXsz7Xz2bLBaY+RxqVLB2LFmynnp0o743Llmyvnnn2vKuYiIiIi8mJR0iyRk6dKZbPjgQVPpLNLx49CggdkHLAZLjxcpAuvXw+TJ4OtrYrdvm23GCxaElStj7FEiIiIiIvGCkm6RF0HOnGZz7S1bTOG1SNu2mdLjVavC7t0x8ig3N2je3Ew5b9/eMeX88GF44w2z9Pzs2Rh5lIiIiIhInKekW+RFUqKEqXC2bJmpdhZp+XIzTP3ee3DqVIw8KmVKGDMGtm+HV191xOfNM1POhw2DsLAYeZSIiIiISJylpFvkRWOxQJUqsGMHTJ8OWbOauM0GM2aAvz98/DFcuRIjjytcGNatg6lTHUXV79yB3r3NlPMVK2LkMSIiIiIicZKSbpEXlZsbNGliSo2PGmU24AZT8Wz0aLPN2MCBMbLNmMUCTZuaKeYdOzqmnB85YvL/d96BM2ee+zEiIiIiInGOkm6RF52npxnZPnECevWCpElN/NYts+1YjhwmCQ8Nfe5HpUwJX39tBtnLlnXEFywwU86HDtWUcxERERFJWJR0i4jh42Oy3mPHoE0bxzZjV6+apNzf35QlDw9/7kcVKgR//QXTppkC6wB378Knn0KBAmbJuYiIiIhIQqCkW0SiypgRxo8324w1bOiInzkD779vFmL/8otZA/4cLBZTt+3wYejUyTHl/OhRqFYN3n4bTp9+rkeIiIiIiLickm4RebicOWHmTNi5E6pXd8QPHjQZ8SuvxMge3z4+Zvb6zp1Rp5z/8gvkzQuffaYp5yIiIiISfynpFpHHK1wYfv/dzAf/995fW7aYPb4rVzb7fT+nggXNI6ZPjzrlvE8fyJ8fli597keIiIiIiMQ6Jd0iEj3lypm9v3791Sy8jrRqldn/+913TSX052CxmILqhw9D587g7m7ix46ZwfY6dWJsG3ERERERkVihpFtEos9igTffhF27zJ7e2bM7js2fD/nywQcfwNmzz/UYHx/46isz5bx8eUd84UIz5Xzw4Bgppi4iIiIi4nRKukXk6bm5QePGZmR73DjHfHCrFX74AXLlgq5dTeXz51CgAKxda/L79OlNLDQU+vUzU86XLHm+1xARERERcTYl3SLy7BInho8+guPHzXZjPj4mHhYGo0aZPb4HDTJ7fj8ji8Xk94cPm53LIqecHz8ONWpA7dqaci4iIiIicZeSbhF5fsmSQa9ecOIE9OgBnp4mfusW9O8Pfn7w9dfPVYY8RQqTx+/aBRUqOOKLFpkp54MGacq5iIiIiMQ9SrpFJOa89BIMH24qn334oWNY+soVUxktd26YMgUiIp75Efnzw5o18NNPkCGDiYWGmtw+Xz5TaF1EREREJK5Q0i0iMS9TJpgwwezp3aCBI37mDLRoYfYH++UXsNme6fYWCzRqZJaUd+3qyO1PnDB13t56y/y7iIiIiIirKekWEefJlQt+/hl27IBq1RzxAwfg7bfhlVfMsPUzSpECRo6E3buhYkVH/NdfISAABg40e32LiIiIiLiKkm4Rcb4iRUyp8T//hDJlHPEtW+C11+CNN2Dbtme+fb588McfJr/PmNHEwsJgwABz7Lffnq/5IiIiIiLPSkm3iMSe8uVh/XpYvNgszo60ciWUKAF165oy5c/AYjEz2Q8dgm7dwMPDxE+ehJo1zZemnIuIiIhIbFPSLSKxy2IxGfCuXTB9OmTL5jg2b54Zmm7VCv7555lunzw5jBhhppxXquSI//abmXI+YICmnIuIiIhI7FHSLSKu4e4OTZqYke2xYyFdOhOPiIDvv4ecOc2Q9dWrz3T7gABYvRpmzYo65XzgQJPXL178zHXcRERERESiTUm3iLhW4sTQrh0cPw6ffWaqo4HJkL/8EnLkgMGDISTkqW9tsUD9+mbKeffuUaec16plKp0fPx6D7yIiIiIi8h9KukUkbkiWDHr3NhnxJ5+Ap6eJ37oF/fqZ5Pubb0wy/pSSJ4cvvoA9e+D11x3xJUvMqHe/fnDnTgy9h4iIiIjIvyjpFpG45aWX4PPP4dgxaN3asQn3lSvQqRP4+8PUqWYa+lPKm9fUbJszx2wlDiaHHzzYJN+LFmnKuYiIiIjELCXdIhI3ZcoEEyfCwYNmjnik06eheXMoWBAWLnzqLNliMUXSDx2CHj0cU85PnYLataFGDZPvi4iIiIjEBCXdIhK35cplqqHt2AFVqzriBw5AnTpQujSsWfPUt/X2huHDYe9eCAx0xJcuNaPefftqyrmIiIiIPD8l3SISPxQpYjLitWtNoh1p82Z47TWoUgW2b3/q2+bJAytWwNy58PLLJnbvHgwZYiqgP8NguoiIiIiInZJuEYlfKlSADRvMAuz8+R3xFSugeHGoV89sQ/YULBZ4910zk71nT0iUyMRPnzaD6dWrw9GjMfgOIiIiIvLCUNItIvGPxQJvvQW7dsG0aZAtm+PY3LlmfnirVvDPP091W29vGDbMTDmvXNkRX7bM5Peffgq3b8fIG4iIiIjIC0JJt4jEX+7u8N57piramDGQNq2JR0TA999DzpzQrRtcu/ZUt/X3h+XLYd48yJzZxO7dg6FDzZTzBQs05VxEREREokdJt4jEf0mSQPv2cPy4WYydIoWJh4XBl1+aPb6HDIGQkGjf0mKBd94xU8579XJMOT9zxsSrVoUjR5zwLiIiIiKSoCjpFpGEw9vbzAE/ccKMcHt6mnhwsClH7udnRsTDwqJ9y2TJzAj3vn3wxhuO+IoVULCghaFDvZ8mlxcRERGRF0ycSbqHDx+OxWKhc+fOjzzn/v37DBo0CD8/Pzw9PSlUqBDLli174Lxx48aRLVs2PD09KVWqFFu2bHFiy0UkzkmdGkaMMNXPWrUy09ABLl+Gjh3N/PFp08w09GjKndus7Z4/H7JkMbH79y2MGeNNQICFn3/WlHMREREReVCcSLq3bt3KxIkTKViw4GPP69OnDxMnTmTMmDEcOHCANm3aUKdOHXbu3Gk/Z/bs2XTp0oX+/fuzY8cOChUqRJUqVbh8+bKzX0NE4pqXX4bvvjN7eter54ifPg3NmkGhQqYKejSzZYsF3n7b3K53b0ic2Fx37pyFRo1MYfXdu53xIiIiIiISX7k86Q4JCaFx48ZMmjSJVKlSPfbc6dOn07t3b6pXr06OHDlo27Yt1atX58svv7SfM2rUKFq1akWLFi0ICAhgwoQJeHl58eOPPzr7VUQkrsqdG2bPNvt4V6niiO/fD7VrQ5kyZv/vaEqWDD77DPbssVG5cqg9vm4dFC0KH3301LXbRERERCSBcnnS3a5dO2rUqEFgYOATzw0LC8Mzco3m/yVNmpT169cDcO/ePbZv3x7lXm5ubgQGBrJp06aYbbiIxD9Fi5o54mvWwCuvOOJ//w2VKpnqaDt2RPt2uXLBtGlB/PqrlVy5TMxqhfHjTZ4/fvxTzWAXERERkQTIw5UPnzVrFjt27GDr1q3ROr9KlSqMGjWK8uXL4+fnx+rVq1mwYAER//+/2qtXrxIREUG6dOmiXJcuXToOHTr0yPuGhYUR9q/CSsHBwQBYrVasVuvTvpbEQVarFZvNpp+nGOXLw/r1sHgxlr59sezfb+LLl8Py5djq1sU2aJDJnB8jsl9VrWrl9dfhm29gyBALISEWrl83I94TJ9oYPdpG+fKx8F6SIOjvK3EW9S1xBvUrcZb40Lei2zaXJd1nz56lU6dOrFy58oHR60f5+uuvadWqFXny5MFiseDn50eLFi2ee+r4sGHDGDhw4APxK1euEBoa+pArJL6xWq3cvHkTm82Gm5vLJ3hIXFG6NCxfjuf8+XiPHInH2bMAWObOhQULuNugASFdumDNmPGhl/+3XzVrBlWquDFkSHLmz08KwO7dFipVslCnzl369LlFxoxx9z8cEjfo7ytxFvUtcQb1K3GW+NC3bt26Fa3zLDaba+rtLly4kDp16uAeWVUYiIiIwGKx4ObmRlhYWJRj/xYaGsq1a9fImDEjPXv25LfffmP//v3cu3cPLy8v5s2bR+3ate3nN2vWjKCgIBYtWvTQ+z1spDtz5szcuHGDFJH7/Uq8ZrVauXLlCr6+vnH2D624WFgYTJqEZcgQLFeu2MM2T09o3x7bJ5+Yquj/8rh+tWEDdO5sYccOiz3m5WWjd28bH3/s2M1M5L/095U4i/qWOIP6lThLfOhbwcHBpEqVips3bz42b3RZ0n3r1i1Onz4dJdaiRQvy5MlDjx49yJ8//xPvcf/+ffLmzUu9evUYOnQoAKVKlaJkyZKMGTMGMD+sLFmy0L59e3r27BmttgUHB+Pj4/PEb57EH1arlcuXL5M2bdo4+4dW4oiQEBg92mw59v+lJgCkSAHdu0PnzmY/cJ7cryIi4McfTaXzq1cd8Rw54KuvoGZNUxFd5N/095U4i/qWOIP6lThLfOhb0c0bXdb65MmTkz9//ihfyZIlI3Xq1PaEu2nTpvTq1ct+zebNm1mwYAEnTpxg3bp1VK1aFavVyieffGI/p0uXLkyaNImpU6dy8OBB2rZty+3bt2nRokWsv6OIxEPe3tCnD5w4Ad26QZIkJh4cDH37gp8fjB0L9+498Vbu7mab8CNHoEMHx3bhJ05ArVpQvTocPuzEdxERERERl4ubvzL4vzNnznDhwgX759DQUPr06UNAQAB16tQhU6ZMrF+/npQpU9rPqV+/PiNHjqRfv34ULlyYXbt2sWzZsgeKq4mIPFbq1Ga0+9gxkzlHZsyXL5sM2t8fpk+PVnnyVKlMkbWdO6FiRUd82TLIn98MoP97UF1EREREEg6XTS+PyzS9POGJD9NTJI47fNiMdM+dGyV8398f988+w+3tt6M1V9xmg3nzoGtX+H/dNgDSp4fPP4cmTUBd9MWmv6/EWdS3xBnUr8RZ4kPfivPTy0VE4hV/f5gzB7ZtgzfesIcTHT6M27vvQsmSZuj6Cb/HtFigbl04dAj69XPMXr94EZo1g7JlzSNEREREJGFQ0i0i8jSKFTP7ef/xB7ZSpRzxbdugWjWzB/iffz7xNl5eMHAgHDwIdeo44ps2mfy9VSszk11ERERE4jcl3SIiz6JSJWwbNnBj2jRshQo54uvXm4Xbb7wBW7Y88TbZs8OCBbBiBeTNa2I2G3z/PeTODV9/DffvO+cVRERERMT5lHSLiDwri4WwypWxbdtmpp7nyeM4tnIllCplypTv3v3EW1WubE4bNcrsTgZw86bZoaxIEVi92jmvICIiIiLOpaRbROR5ubmZhdr79sHUqWb4OtLixVC4MDRoYBZyP0aiRPDxx2aLsfffd8T374fAQHj3XTh1yilvICIiIiJOoqRbRCSmuLtD06YmuZ4wATJlchybPRvy5YMWLeDkycfeJl06+OEH2LzZrO+ONH++mYI+cCDcveukdxARERGRGKWkW0QkpiVODB9+aPb4/uor8PU1casVpkwxldA/+gjOnXvsbUqWNIXVJk+GtGlNLDQUBgwwyff8+U8sli4iIiIiLqakW0TEWTw9zaLsEydg6FBImdLE79+H8eMhZ06zYfdjypS7uUHz5mbKeZcu4OFh4qdPm+nmlSub6eciIiIiEjcp6RYRcTZvb+jVy0wr79vXfAYzbD1qFOTIAX36wI0bj7yFjw98+SXs2WMS7UirV0OhQia3Dwpy6luIiIiIyDNQ0i0iEltSpoRBg8zId7duZiQc4PZt+Owzk3x/9hncuvXIW+TNa7YJ/+UXyJbNxCIizNZiuXObrcYiIpz+JiIiIiISTUq6RURim68vjBgBx49Du3ambDmYoeo+fUzyPWrUI6ulWSxQuzYcOACDB0PSpCZ+5Qq0amV2Ktu0KVbeRERERESeQEm3iIirZMwIY8c69ghzdzfxq1fNWm8/P/j2W7h376GXJ01qcvRDh6B+fUd8+3YoUwaaNYMLF2LhPURERETkkZR0i4i4WrZsZo+wAwegYUMzlA0mY27XzlQ7nzIFwsMfenmWLDBrFqxdCwUKOOLTpplLR458ZN4uIiIiIk6mpFtEJK7InRtmzoTdu8388UinTpn9vfPlM9m11frQyytUgB07zOB5qlQmdusWdO9ukvFly5z+BiIiIiLyH0q6RUTimgIFTKW0LVugShVH/MgRMxJeuDAsWvTQTbo9PMzg+JEjZqvwyEHzI0egWjWoVcssJRcRERGR2KGkW0QkripRwgxP//knlCvniO/da0bCX3kFVq58aPKdJg1MmGDWd7/6qiO+eDEEBMCnn5qi6SIiIiLiXEq6RUTiuvLlTeK9fLlJxCNt2QJvvAEVK8K6dQ+9tEgRc2jGDMiQwcTu3YOhQ81671mzHpqzi4iIiEgMUdItIhIfWCwmwd68GRYujFox7a+/TGJetSps3frQSxs3hsOHoWdPxw5l586Z2eoVKphl5CIiIiIS85R0i4jEJxaLWZi9axf8/LMpvhZp+XIoWRLq1DFT0P8jeXIYNgz274caNRzxdeugaFH46CO4ds35ryAiIiLyIlHSLSISH7m5QYMGJoP+8UfImtVxbOFCKFQIGjUyFdT+I1cu+O0385Url4lZrTB+vMnhx4+HiIjYeQ0RERGRhE5Jt4hIfObhYbYTO3IExo1zLNy22cxIeEAAtGwJp08/cGmNGmZA/PPPwdvbxK5fNyPexYqZWesiIiIi8nyUdIuIJASJE5ts+fhxGDnSlC8HM2T9449mSLt9ezh/PsplSZLAJ5+Y9d5Nmjjiu3ebtd6NGsE//8Tie4iIiIgkMEq6RUQSkqRJoWtXOHECBg8GHx8Tv3/fjIT7+UH37nD1apTLMmaE6dNh/XpT8TzSzz+bKudDh0JoaCy+h4iIiEgCoaRbRCQhSp4c+vSBkyehd29IlszEQ0PNSHj27NCvHwQFRbns1VdNAfSJEyF1ahO7c8fs650/P/z6q7YYExEREXkaSrpFRBKyVKngs8/MyPfHH5v55AAhIWYkPEcOU9I8JMR+ibs7tG4NR49Chw6mZhuYmetvvQXVq5vp6CIiIiLyZEq6RUReBGnTwqhRJnNu08YUYAO4ccOMhPv5wejRUeaQp0oF33xjdierWNFxq2XLzKh39+4QHBybLyEiIiIS/yjpFhF5kWTKZPYEO3IEmjVzDGNfvmxGwnPmNHPL792zX1KgAPzxB8yZA5kzm1h4uJml7u8P06aZLcdERERE5EFKukVEXkTZs8OUKWaf73r1HPFz58xIeJ48Jpv+/4bdFgvUrQsHD0Lfvo5Z6hcvmty9bFnYti32X0NEREQkrlPSLSLyIsuTB2bPNnPIa9Z0xE+eNNl0/vwwd659KDtZMhg0yCTfdeo4Tt+0CUqWhFatzKC5iIiIiBhKukVEBAoVgsWL4e+/ITDQET90yIyEFysGv/1mL12ePTssWAArVkDevOZUmw2+/x5y54avvza7lImIiIi86JR0i4iIQ6lSsHIlrFlj9g+LFDkSXqYMrF5tT74rV4bdu02NthQpzKk3b0Lnzma/79WrY/0NREREROIUJd0iIvKgihVh3TpYutSMckeKHAl/7TXYuBGARIlMDbYjR6BFC8ep+/ebU999F06ditXWi4iIiMQZSrpFROThLBaoWhW2bjVzyfPlcxxbu9aMhFevDjt2AJAuHfz4I2zebNZ3R5o/30xBHzAA7tyJ1TcQERERcTkl3SIi8ngWi6matns3/PST2VYsUuRI+DvvmKFtTMK9aZNJwNOmNaeFhsLAgaZu288/22eni4iIiCR4SrpFRCR63N2hUSM4cMBUTMuSxXFswQKzoXeTJnDsGG5uZqr5kSPQpQt4eJjTzp41tyhb1gygi4iIiCR0SrpFROTpJEoELVuajHrMGEif3sRtNjMSnieP2TvszBl8fODLL2HPHqhWzXGLjRvNiHjz5nD+vEveQkRERCRWKOkWEZFnkyQJtG8Px4/DF1/ASy+ZeESEGQnPlQs6doSLF8mbF5YsMV/+/o5bTJ1qthgbOtRMQRcRERFJaJR0i4jI8/Hygu7d4eRJs3A7cu+we/fMSHiOHNCjB1y7RrVqsHcvjB4NKVOa027fhk8/NcXW5s3Tem8RERFJWJR0i4hIzEiRAvr1gxMnoGdPk4wD3L1rRsKzZ4e+fUkUcoNOneDoUfjoI3D7/3+JTp2CunXNbmU7d7rqJURERERilpJuERGJWalTw7BhZtp5p06QOLGJ37oFQ4ZAtmwwYABpPIIYN84URQ8MdFz+11+mIHqrVnDpkkveQERERCTGKOkWERHnSJ/ezCM/dgxat3aUMA8ONtPQs2eHQYPIn/kmK1bAokWO3chsNsey8BEjICzMZW8hIiIi8lyUdIuIiHNlzgwTJ5pq5y1bmq3HAIKCoH9/yJ4dy2dDeKtiMPv2mSQ7cln4rVvwySeQLx8sXKj13iIiIhL/KOkWEZHYkT27Gb4+csRs4h2ZfN+4AX37QvbsJBk1jG4f3uLoUTO93GIxpxw/DnXqQOXKphCbiIiISHyhpFtERGJXjhzw449w6BA0a+aopHb9OvTuDdmzk3by53w3KoQdO6BCBcelq1dD4cLQti1cueKS1ouIiIg8FSXdIiLiGjlzwpQpcPAgNGniSL6vXTPVz7Nnp/Cqkaz57Tbz55uBcgCrFSZMMOu9v/rK7EwmIiIiElcp6RYREdfKnRumT4cDB6BRI8ec8qtXoXt3LH45ePvUKA5su8OwYeDtbQ7fvAldukCBAvD771rvLSIiInGTkm4REYkb/P3hp59g/35o0MCRfF++DF274hmQg56eozmy+y4tWjgOHzkCb74J1aqZvF1EREQkLlHSLSIicUvevPDzz6ZiWt26jvilS/Dxx2Qo68ePhb9h2/pQXn3VcXj5cihYEDp2NMvDRUREROICJd0iIhI35csHc+bAnj3wzjuO+IUL0KkTRev6sa7BOOZMDyNLFnMoIgLGjDHLxceMgfv3XdN0ERERkUhKukVEJG4rUADmzYNdu8y+YZHOn8fSoT11e+XkaJfxfNYvDC8vc+jGDTPiXaiQGQEXERERcRUl3SIiEj8UKgQLFsCOHVCrliP+zz8k7vwRvSfn4p9+E2neyFHO/OBBqFrVrPk+fNgFbRYREZEXnpJuERGJX4oUgYULYds2k01HOnuWVD3bMHlDbo73+p5XSzrmlv/+O+TPb6qdBwXFeotFRETkBaakW0RE4qdixeDXX2HLFqhe3RE/fZocw1qx7oo/G1v9SNaMJvkODzf7eufKZfb5Dg93UbtFRETkhaKkW0RE4rcSJcxQ9t9/m7nk/2c5eZLSk1pyIkkeFrw1hWRJTJZ99Sq0bQtFi8Iff7iq0SIiIvKiUNItIiIJQ6lSsHQpbNwIlSvbw24nT1BncQtuZMjLuFLTcMck33v3wuuvm9psx465qtEiIiKS0CnpFhGRhKV0aVixAtavN1n1/yU6dYyPNjfjVuZ8fJrtJ9yIAMzy8Hz54JNPIDjYRW0WERGRBEtJt4iIJEyvvgqrVsFff0GlSvZw0rNHGHKqCdcy5KeNz8+4EcG9ezBihFnv/f33Zr9vERERkZigpFtERBK2cuXM4u01a6B8eXs45YVDjL/ZiAupC9DYYzYWrFy+DK1amWXif/3lwjaLiIhIgqGkW0REXgwVK8LatbB6NZQtaw+nvXaQGeENOJmiEO8wDwtWdu6EChWgbl04dcpVDRYREZGEQEm3iIi8OCwWeO01M4y9ciWUKWM/lDV4H/Ooy0HPItRhARaszJsHefLAp59CSIgL2y0iIiLxlpJuERF58VgsEBhoiq0tXw6vvGI/5B+6hwW8wx6PotRiIWFhNoYOhdy5YepUsFpd2G4RERGJd5R0i4jIi8tigTfeMNuMLVliFnP/X/7w3SykDjsoRk0Wc+GCjebNzc5kGza4rskiIiISv8SZpHv48OFYLBY6d+782PNGjx6Nv78/SZMmJXPmzHz88ceEhobajw8YMACLxRLlK0+ePE5uvYiIxGsWC1SrBps3w2+/QbFi9kNF2MliarGFklTnd7Zts1G2LDRsCGfOuLDNIiIiEi/EiaR769atTJw4kYIFCz72vJkzZ9KzZ0/69+/PwYMH+eGHH5g9eza9e/eOcl6+fPm4cOGC/Wv9+vXObL6IiCQUFgvUqAFbt8LixVCkiP1QCbbxO2/yN69QlaXMmmUjTx7o3x9u33Zhm0VERCROc3nSHRISQuPGjZk0aRKpUqV67LkbN27k1VdfpVGjRmTLlo033niDhg0bsmXLlijneXh4kD59evtXmjRpnPkKIiKS0FgsULMmbN8OCxdCoUL2Q6XYwlKqs4nSlLu7nEGDbPj7w08/gc3muiaLiIhI3OTh6ga0a9eOGjVqEBgYyJAhQx57bpkyZZgxYwZbtmyhZMmSnDhxgiVLlvDee+9FOe/o0aNkzJgRT09PSpcuzbBhw8iSJcsj7xsWFkZYWJj9c3BwMABWqxWrKuYkCFarFZvNpp+nxCj1qxdEzZpm9HvhQiyDBmHZuxeAV9jMcqqygTIMODeAJk0CGTsWvvrKRsmSz/449StxFvUtcQb1K3GW+NC3ots2lybds2bNYseOHWzdujVa5zdq1IirV69StmxZbDYb4eHhtGnTJsr08lKlSjFlyhT8/f25cOECAwcOpFy5cuzbt4/kyZM/9L7Dhg1j4MCBD8SvXLkSZb24xF9Wq5WbN29is9lwc3P5BA9JINSvXjBly8KyZSRZsgTvkSNJdPgwAK+ykZW8wTrK0v/vgZQuXYl33w2ld+9bZMjw9P+joH4lzqK+Jc6gfiXOEh/61q1bt6J1nsVmc81kuLNnz1K8eHFWrlxpX8tdsWJFChcuzOjRox96zdq1a2nQoAFDhgyhVKlSHDt2jE6dOtGqVSv69u370GuCgoLImjUro0aNomXLlg8952Ej3ZkzZ+bGjRukSJHi+V5U4gSr1cqVK1fw9fWNs39oJf5Rv3qBWa0wbx6WwYOxHDgQ5dCflKcfg9jmVZ6ePW106QJJkz7NrdWvxDnUt8QZ1K/EWeJD3woODiZVqlTcvHnzsXmjy5LuhQsXUqdOHdzd3e2xiIgILBYLbm5uhIWFRTkGUK5cOV555RVGjBhhj82YMYPWrVsTEhLyyB9GiRIlCAwMZNiwYdFqW3BwMD4+Pk/85kn8YbVauXz5MmnTpo2zf2gl/lG/EiIiYM4cGDQIDh2KcugPKtGfgZzNWo4vvoC6dc1S8SdRvxJnUd8SZ1C/EmeJD30runmjy1r/+uuvs3fvXnbt2mX/Kl68OI0bN2bXrl0PJNwAd+7ceeAbHnneo353EBISwvHjx8mQIUPMv4SIiLzY3N3N3mH79sGMGZA7t/3Qa6xhHeX5/nQgX9ffQPnypi6biIiIvFieKek+e/Ys//zzj/3zli1b6Ny5M999912075E8eXLy588f5StZsmSkTp2a/PnzA9C0aVN69eplv6ZmzZqMHz+eWbNmcfLkSVauXEnfvn2pWbOmPfnu1q0bf/75J6dOnWLjxo320fSGDRs+y6uKiIg8mbs7NG4M+/fDtGmQM6f9UCCr2UBZ+q5/gw7FN/H++3DxogvbKiIiIrHqmZLuRo0asWbNGgAuXrxI5cqV2bJlC59++imDBg2KscadOXOGCxcu2D/36dOHrl270qdPHwICAmjZsiVVqlRh4sSJ9nP++ecfGjZsiL+/P/Xq1SN16tT8/fff+Pr6xli7REREHsrDA957Dw4ehClTsOXIYT/0BivZSBnqTa5KwxybGT4cVKtTREQk4XumNd2pUqXi77//xt/fn2+++YbZs2ezYcMGVqxYQZs2bThx4oQz2hprtKY74YkPa0Ik/lG/kie6fx+mT8c2eAiWUyejHPqd6kzKOICmY0pQp45jvbf6lTiL+pY4g/qVOEt86FtOXdN9//59kiRJAsCqVat46623AMiTJ0+UkWkREZEXWqJE8P77WI4chkmTiMic1X6oBktYeL4kid6pSZsS29m924XtFBEREad5pqQ7X758TJgwgXXr1rFy5UqqVq0KwPnz50mdOnWMNlBERCTeS5QIPvgA92NHYOJE7mXIYj9Uk9+YuL04pwvXYsg7O7l82YXtFBERkRj3TEn3559/zsSJE6lYsSINGzakUKFCACxevJiSJUvGaANFREQSjMSJoXVrEp88gu3b8dxJ/bL90Fssps+ComzN/C6/DDzBvXsubKeIiIjEmGfepzsiIsK+GXikU6dO4eXlRdq0aWOsga6gNd0JT3xYEyLxj/qVPLewMO5P+J7QfkNJHnw+yqHlyerg3r8vr3crEq39vUWeRH9niTOoX4mzxIe+5dQ13Xfv3iUsLMyecJ8+fZrRo0dz+PDheJ9wi4iIxJokSUjUqR3JLx0neMg3BHllsB+qcvsXAj8pysbUNTkwZYsLGykiIiLP45mS7lq1ajFt2jQAgoKCKFWqFF9++SW1a9dm/PjxMdpAERGRBM/TkxSfdiDl1eOc6fIVVxM5ku9Xb/xGQItS7M5YlYsLNrqwkSIiIvIsninp3rFjB+XKlQNg3rx5pEuXjtOnTzNt2jS++eabGG2giIjICyNpUl4e0ZH7hzeyu9UYLng41nwXurCc9O+8yvFsr3N7yZ8ubKSIiIg8jWdKuu/cuUPy5MkBWLFiBW+//TZubm688sornD59OkYbKCIi8qKxJPWkwISPSHPjGH/Un8gZN8dWY36n/yBZjYqcz12BiOWr4NlKs4iIiEgseaakO2fOnCxcuJCzZ8+yfPly3njjDQAuX76swmMiIiIxJJF3El6b1ZoUF48yu8qPHMfPfizj0b9wr1qZG/lehaVLlXyLiIjEUc+UdPfr149u3bqRLVs2SpYsSenSpQEz6l2kSJEYbaCIiMiLLqVvIuova4Hl8CHGlJzOIfztx1Id3ATVq3OnQElYvFjJt4iISBzzTEn3u+++y5kzZ9i2bRvLly+3x19//XW++uqrGGuciIiIOOTI7UGHzU249ud++uT8mX3ksx/z2r8NatXifsGiMH8+WK0ubKmIiIhEeuYNz9KnT0+RIkU4f/48//zzDwAlS5YkT548MdY4ERERedCr5d0ZfKQB+37aQ5s089hFIfuxRPt2wbvvYs1fEGbNgogI1zVUREREni3ptlqtDBo0CB8fH7JmzUrWrFlJmTIlgwcPxqrfrIuIiDidxQINGrkx+uw7LB+2kwZJF7GV4vbjbgf3Q8OG2PLlgxkzIDzcha0VERF5cT1T0v3pp58yduxYhg8fzs6dO9m5cydDhw5lzJgx9O3bN6bbKCIiIo/g6Qk9eloYc/otprTdwptuS9jEK/bjlsOH4b33IE8emDwZ7t93YWtFRERePM+UdE+dOpXvv/+etm3bUrBgQQoWLMhHH33EpEmTmDJlSgw3UURERJ7E1xfGfWthxL5qfFZ9I4Gs5C/KOU44fhzefx9y54bvvoOwMNc1VkRE5AXyTEn39evXH7p2O0+ePFy/fv25GyUiIiLPJm9e+O13C71WBdKx0F9UYC2reN1xwqlT8OGHkDMnjBsHoaEua6uIiMiL4JmS7kKFCjF27NgH4mPHjqVgwYLP3SgRERF5Pq+/Dtu3Q7MfKtA0wyrKsIGlVHWc8M8/0L495MgBo0fDnTsua6uIiEhC9kxJ9xdffMGPP/5IQEAALVu2pGXLlgQEBDBlyhRGjhwZ020UERGRZ+DubmaUHzkCb/Qvw7teSynJZhZT03HShQvw8ceQPTuMGAEhIa5rsIiISAL0TEl3hQoVOHLkCHXq1CEoKIigoCDefvtt9u/fz/Tp02O6jSIiIvIcvL1hwACTfOdrXpLalsUUYQfzedtx0uXL8MknkC0bDB0KwcGuaq6IiEiCYrHZbLaYutnu3bspWrQoEfF8T9Dg4GB8fHy4efMmKVKkcHVzJAZYrVYuX75M2rRpcXN75u3pRaJQvxJniI1+tXMndOsGf/wB+dnLp3xGPebgxr/+lyBlSujcGTp2hFSpnNIOiV36O0ucQf1KnCU+9K3o5o1xs/UiIiLiNEWKwKpVsHgx3PcvQENmkY/9zKAxEZH/axAUZIbHs2WDPn3g2jUXtlhERCT+UtItIiLyArJYoGZN2LsXxo6FK6nz8h4zyMMhJtOccNzNicHB8NlnJvnu0cNMQxcREZFoU9ItIiLyAkuUCNq1g2PHoHt3OJM4F+8zmdwc4TtacZ9E5sSQEPjiC5N8d+1qCrCJiIjIE3k8zclvv/32Y48HBQU9T1tERETERVKmNDl127bQsyfMmZODD/mOIfShB5/TyvI9iW334O5dGDXK7PHdurUpvvbyy65uvoiISJz1VCPdPj4+j/3KmjUrTZs2dVZbRURExMmyZ4fZs2HjRnjlFThLFtozjuy2E3xNJ+65e5oTw8JgzBjw8zOZ+unTrm24iIhIHBWj1csTClUvT3jiQ/VDiX/Ur8QZ4lK/stlgzhwz8n3qlIml4yI9E33JR3xL4vt3HCd7eECzZtCrl0nEJc6JS31LEg71K3GW+NC3VL1cREREnovFAvXrw8GDZup5ihRwifR8fH8Eme6fYox3L+55Jjcnh4fDDz+Av79Jvg8fdm3jRURE4ggl3SIiIvJYnp6myNqxY6bomrs7XMWXjiFDSR96iu/S9+N+Mh9zckQETJsGAQHQqBHs3+/axouIiLiYkm4RERGJFl9fs73Yvn1muzGAG7zEhxcHkub2aWbkGUyEz0vmgNUKP/8MBQpA3bqwe7frGi4iIuJCSrpFRETkqeTJA4sXw+rVULiwiQXjw3uH+pAm5BSLywzHmsbXHLDZYN48c2Lt2rB9u4taLSIi4hpKukVEROSZvPYabNsGkydDhgwmFhSRnFobe/DyvZOsefNLbOnSOS5YtAiKF4caNeDvv13TaBERkVimpFtERESembs7NG8OR4/CgAHg5WXiF4KT8dpvXQjwPMnOFt9gy5TJcdGSJVC6NLzxBqxb54pmi4iIxBol3SIiIvLckiWD/v1N8t2ihal8DnDodFKKTu5ApczHOfnJeMiSxXHRypVQvjxUqgRr1pip6CIiIgmMkm4RERGJMRkzwo8/wo4d8PrrjviffychxxdtaFLqKFeHfw85cjgOrl1r5qqXKwcrVij5FhGRBEVJt4iIiMS4woXNQPZvv5nCa5F+mpuYl/u3pPc7h7kzfirkyuU4uGEDVKkCr7wCv/+u5FtERBIEJd0iIiLiFBaLqZm2Zw+MGwdp0ph4WBgMG+FB1r5NGd/xIBHTZ0LevI4Lt2yBN980RdcWLjTbj4mIiMRTSrpFRETEqRIlgo8+gmPHoEcPSJzYxK9ehY86uFNgaEN+/3wfttlzoGBBx4U7dkCdOmbYfO5cJd8iIhIvKekWERGRWOHjA8OHw+HD0KCBI37wILz5lhuVv6vL7ik74ZdfoGhRxwl790K9epA/P8ycCRERsd94ERGRZ6SkW0RERGJVtmzw88+waZPZOSzS6tVQpJgbLX+tzfnF28yC8FKlHCccPAiNG0NAAEydCuHhsd52ERGRp6WkW0RERFzilVdM7bQ5cyB7dhOz2Uz181y5LQzaXoPbqzaZiuZlyzouPHLEbA7u7w/ffw/37rmk/SIiItGhpFtERERcxmKBunXNIPaIEWYKOsCdO2bf79z+Fqacq4x17V9mL+9KlRwXnzgBrVpBzpwwZoy5SEREJI5R0i0iIiIulyQJdOtmiq116AAeHiZ+/jy0aAHFilv4w1oR/vgD1q2DN95wXHz2LHTsaOatDx0KQUEueAMREZGHU9ItIiIicUaaNPDNN7BvH7z1liO+axe8/rqJHfYtC8uXw99/m63FIl25Ap9+ClmzQq9ecOlSrLdfRETkv5R0i4iISJzj7w+LFpmB7SJFHPFffzVFzDt0gKt+pUxgzx5o1Ajc/v+/NcHBpkx6tmzQvj2cPu2SdxAREQEl3SIiIhKHVaoE27bBlCmQKZOJhYfD2LFmKfeIERCWuwD89JMpsNa6tWMj8NBQGDfOnNismVk4LiIiEsuUdIuIiEic5uZmcuYjR2DQIEiWzMRv3oRPPoE8eUzObc3uBxMnwsmT0LWr48TwcJg2DfLlg7ffhq1bXfcyIiLywlHSLSIiIvGClxf07QtHj0LLlqbyOcCpU9CkCRQvDqtWARkzwsiRZlr5gAGQKpU50WaDX36BkiVNIbY1a0xMRETEiZR0i4iISLySIYPZnnvnTqhSxRHfuRMqV4aqVWH3biB1arPv2OnTJgnPkMFx8sqV8NprUKaMWRdutcb6e4iIyItBSbeIiIjES4UKwbJlJn/+d7G15cvN56ZN/19DLXlyM9385Ekz/TxHDsfJf/9tSqIXKgQzZ5qp6CIiIjFISbeIiIjEa4GBptjajBlmtzAws8anTzdV0Lt3hxs3MJuBt24Nhw+bBLtAAcdN9u2Dxo3NBRMnmiJsIiIiMUBJt4iIiMR7bm4mZz58GL780rGMOyzMzCzPkcP8MzQU8PCAhg3NHPRff4XSpR03OnEC2rRxXHDrlkveR0REEg4l3SIiIpJgJEkCXbqY3LlHD/D0NPGgIDPi7e9vRsCtVkwltjffhA0bYO1aU1wt0oUL5oKsWU0xtmvXYv9lREQkQVDSLSIiIglOypQwfLjZZqx5c0el8zNnzFrvokVhxYr/n2yxQIUKZjH41q1mW7HIC27cgIEDTfLdtSucO+eCtxERkfhMSbeIiIgkWJkzw+TJsGsXVKvmiO/ebSqfV65sqp7bFS8O8+fD/v1mc3APDxO/fRtGjTLTzlu3hmPHYvM1REQkHlPSLSIiIglewYKwZAmsXg3Fijniq1aZUe8mTcx+33Z588KUKSa5bt/eMU/93j2YNMnMU2/YEPbsicW3EBGR+EhJt4iIiLwwXnsNtmyBn3+G7Nkd8Z9+Mnl0167/Wb6dNSuMGWMy8l69IEUKE7daYdYss9XYm2/Cxo2x+RoiIhKPKOkWERGRF4qbGzRoAAcPwujRkDq1id+7Z2aQ+/nB55/D3bv/uihdOhg61CwKHzoUfH0dx37/HV59FSpWNOvCbbZYfBsREYnrlHSLiIjICylJEujUCY4fN4PYkTPIb96Enj0hd24zwzwi4l8X+fiYk0+dgm++MYvGI/35J1St6lgXbrXG4tuIiEhcpaRbREREXmg+Pmbw+uhReP99MxIO8M8/0KIFFCkCS5f+ZwDbyws6dDBrvidPNnPTI+3YAe++CwEBJmu/fz82X0dEROIYJd0iIiIiwMsvww8/mMrmNWo44nv3QvXq8PrrsG3bfy5KnNjsSbZ/P8ybZ6qyRTp82GTtfn5mXfidO7HxGiIiEsco6RYRERH5l/z54bffYO1aKFHCEV+zxnxu2BBOnPjPRe7u8M47Jitfvtzs+x3p7Fno2BGyZTND6kFBzn8JERGJM+JM0j18+HAsFgudO3d+7HmjR4/G39+fpEmTkjlzZj7++GNCQ0OjnDNu3DiyZcuGp6cnpUqVYsuWLU5suYiIiCREFSrA5s0wZ44ZrI40axbkyQOdO8PVq/+5yGKBN94wGfuGDaayeaQrV+DTT01F9F694NKlWHgLERFxtTiRdG/dupWJEydSsGDBx543c+ZMevbsSf/+/Tl48CA//PADs2fPpnfv3vZzZs+eTZcuXejfvz87duygUKFCVKlShcuXLzv7NURERCSBsVigbl04cMDMEE+TxsTv34evvzbJ+LBhj5g5XqYM/Pqrma/esKFjsXhwMAwfbka+O3SA06dj63VERMQFXJ50h4SE0LhxYyZNmkSqVKkee+7GjRt59dVXadSoEdmyZeONN96gYcOGUUayR40aRatWrWjRogUBAQFMmDABLy8vfvzxR2e/ioiIiCRQiRND+/am0nmfPqaOGpj8uXdvU+n8hx/+U+k8UsGCMHOmWePdqhUkSmTioaEwdizkzGnWhR88GFuvIyIiscjlSXe7du2oUaMGgYGBTzy3TJkybN++3Z5knzhxgiVLllC9enUA7t27x/bt26Pcy83NjcDAQDZt2uScFxAREZEXRooUMHiwqXTeqpVj8PrcOfjgAyhUyKwHf+hW3TlzwnffwcmT0KWLI3MPD4epUyFfPse6cBERSTA8XPnwWbNmsWPHDrZu3Rqt8xs1asTVq1cpW7YsNpuN8PBw2rRpY59efvXqVSIiIkiXLl2U69KlS8ehQ4ceed+wsDDCwsLsn4ODgwGwWq1YtcdmgmC1WrHZbPp5SoxSvxJnUL+KH9KnhwkTTH203r0t/PqrBTBFzGvWhPLlbXz+uY2SJR9ycYYMMGIE9OyJZexYGDMGy40bJlNfsAAWLMBWuTK2nj3NwnKLJUbarL4lzqB+Jc4SH/pWdNvmsqT77NmzdOrUiZUrV+Lp6Rmta9auXcvQoUP59ttvKVWqFMeOHaNTp04MHjyYvn37PnNbhg0bxsCBAx+IX7ly5YEibRI/Wa1Wbt68ic1mw83N5RM8JIFQvxJnUL+KX9KkMYPXf/+diMGDk7NjR2IA/vrLQunSFmrWvEuvXiFkz/6weedA27ZY3nuPpNOnk2ziRNz/X1zNsnIllpUruVe8OLc7dCCscuXnTr7Vt8QZ1K/EWeJD37p161a0zrPYbA+dAOV0CxcupE6dOri7u9tjERERWCwW3NzcCAsLi3IMoFy5crzyyiuMGDHCHpsxYwatW7cmJCSE8PBwvLy8mDdvHrVr17af06xZM4KCgli0aNFD2/Kwke7MmTNz48YNUqRIEUNvLK5ktVq5cuUKvr6+cfYPrcQ/6lfiDOpX8VfkQPWnn1o4etSRIHt42PjwQ+jTx0batI+5QWgoTJ2KZeRILP/Zk8xWoAC2Tz6BevXA49nGTNS3xBnUr8RZ4kPfCg4OJlWqVNy8efOxeaPLRrpff/119u7dGyXWokUL8uTJQ48ePR5IuAHu3LnzwDc88jybzUbixIkpVqwYq1evtifdVquV1atX0759+0e2JUmSJCRJkuSBuJubW5z9AcvTi/yFjn6mEpPUr8QZ1K/ir7p1oXZtmDQJBg6Ey5chPNzCuHEwbZqFTz6Bjz+GZMkecrGXF7RtaxaLz5ljyqLv2weAZe9eLO+9B/37Q48e0KwZPOT/XZ5EfUucQf1KnCWu963otstlrU+ePDn58+eP8pUsWTJSp05N/vz5AWjatCm9evWyX1OzZk3Gjx/PrFmzOHnyJCtXrqRv377UrFnTnnx36dKFSZMmMXXqVA4ePEjbtm25ffs2LVq0cMl7ioiIyIslUSL46CM4dgz69XPUS7t1C/r2hVy5TFIeHv6IG3h4QKNGZquxxYuhVCnHsRMn4MMPIXt2+PJLCAlx+vuIiMjziZu/Mvi/M2fOcOHCBfvnPn360LVrV/r06UNAQAAtW7akSpUqTJw40X5O/fr1GTlyJP369aNw4cLs2rWLZcuWPVBcTURERMSZkic3o93Hjpk8OXIS34UL0Lq12Uls0aJHVDoHUxq9Zk3YtAn++AMqV3Ycu3ABunWDLFlgwAC4ds3ZryMiIs/IZWu647Lg4GB8fHyeODdf4g+r1crly5dJmzZtnJ2eIvGP+pU4g/pVwnX4MPTqBb/8EjVetqwpZv7KK9G4ydatZtr5f2+SLBm0aWO2IsuY8aGXqm+JM6hfibPEh74V3bwxbrZeREREJIHx9zeF1tavhzJlHPH166F0aXj3XThy5Ak3KVHC3GT/fmja1DF8fvu2mW6ePbsZVj9+3GnvISIiT0dJt4iIiEgsevVVk2j/8otJxCPNnw8BAdCuHfx/57BHCwiAqVPN3PV27SBy+9V798weZrlzm3Xhe/Y47T1ERCR6lHSLiIiIxDKLxVQ537cPJkyAyNIzERHw7beQM6dZD/7EOmnZssHYsXDqFPTsaRaSA1it8PPPUKiQY124iIi4hJJuERERERfx8DCzwY8dM0l25FZiISGmPlrOnCYpv3//CTdKl86s9T5zBj77DNKkcRz77TcoUwbLa6+ReM2ax1RuExERZ1DSLSIiIuJi3t5me7Hjx812Yx4eJn7pktm6u0ABMx39iflyypTQuzecPg1ffw2ZM9sPWf78k5caNcJSrBjMmBGNTF5ERGKCkm4RERGROCJdOhg3ztRJe+cdR/zwYXj7bVPpfOPGaNzIyws6djRD6D/+aNZ4/59l92547z3w84OvvjIbiIuIiNMo6RYRERGJY3LnhnnzTIJdtqwjvnGjKcRWpw4cOhSNGyVODC1awIEDWGfP5l6RIo5jZ8+aLcayZDGj4xcvxvh7iIiIkm4RERGROKt0afjrL1i0CPLmdcQXLoT8+c3W3BcuRONG7u7w7rtc//13rGvWQI0ajmNBQWY9eNas0KqVGVYXEZEYo6RbREREJA6zWOCtt8zuX999BxkymHhEBEycaIqt9e8fzVniFguUL2+Kq+3bB82bQ6JE5ti9e/D99ya7r10bNmxw0huJiLxYlHSLiIiIxAMeHmYg+uhRGDLEsTvYnTswaJBJvr/99inqo+XLB5Mnw8mT8MknkCKFidtsZmi9bFkzl33hQrMFmYiIPBMl3SIiIiLxSLJk8OmnptJ5hw6OSueXL0O7diaXnjfvKXYGy5QJPv/cbDc2YgRkzOg4tnGjWUAeEACTJkFoaIy/j4hIQqekW0RERCQe8vWFb76BgwehXj1H/OhRqFsXypSBdeue4oY+PtCtmxn5njLFZO+RDh+G1q0hWzYYOhRu3IihtxARSfiUdIuIiIjEYzlzwuzZsHkzVKjgiP/9t1m+XauWScyjLXFiaNYM9u6F33+PetNLl8wwe+bM8PHHZnRcREQeS0m3iIiISAJQsiSsWWNqpP17kHrxYlPpvHVrCxcvPsX/+lksUL06rF0LW7aY4XO3/19/+zaMHg05ckCTJrB7d0y+iohIgqKkW0RERCSBsFjMbmC7d8MPPziWZ1ut8MMPFkqX9qVXL8vTzw4vUQLmzIEjR+Cjj8DT08QjIuCnn6BwYahSBVateorF5CIiLwYl3SIiIiIJjLs7vP++Wd89dKijMHloqIUvvrCQPbuJ3779lDf284Nx48y08v79IXVqx7EVK6ByZShaFH7+GcLDY+x9RETiMyXdIiIiIgmUlxf06mUqnXfqZCNxYjMKffOmWZrt5wdjx5otup+Kry8MGGCS77FjIXt2x7Fdu6BRI7PY/JtvICQkpl5HRCReUtItIiIiksClSQOjRtnYsOEKLVrY7EuzL10y247lyQPTp5vZ4k/Fy8vsU3bkiKnmVqyY49jp09CpE2TJAn36mIeJiLyAlHSLiIiIvCBeftnK99/b2L8f3n3XET95Epo2hUKFYNGiZ1iW7eFh9i3buhX++AOqVXMcu3EDPvsMsmaFDz80CbqIyAtESbeIiIjICyZPHpg71+TIlSs74vv3Q+3a/2vvzuN0LtcHjn+esY7JXraQXbKlOCXqcKjIKVoPR9EqRdEqlVJp02lfhKPltKkUOalOUoRsh2wVyV6INoMizczvj/uMp/m1M89855n5vF+veZ3c9zPzvZ7cOq7nvu/rCj2+p07dix8ci0H79vDaa7B4ccjkixYNc7t2wahR4eGnnBJ6mklSIWDSLUmSVEi1bBnqn739NhxxRHx89uyQOx9/PMyfv5c/vGlTePJJWLUKrrgC9tsvjGdlwfjx0Lo1HH00/Pvfoby6JBVQJt2SJEmFXPv2MGsWTJgAhxwSH3/zzZCYn346LFu2lz+8Rg34xz9g/Xq44w6oUiU+N2MGnHRSaCz+2GNhN1ySChiTbkmSJBGLQdeu4VT4k09CrVrxuXHjQl58/vkhd94r5crBoEGwZk1oIt6oUXxu2TI477xQBf2OO+Cbb/b6fUhSfmPSLUmSpD2KFAlXsZctgwcfhMqVw3hmZsiV69eHyy+HLVv28gElSoQm4kuXwsSJ4Yh5to0bQ4+zGjXCkfS9zvAlKf8w6ZYkSdJPlCgB/fuHHt+33gply4bxXbvg3nuhTp3Qqjs9fS8fkJICJ54I774bzrafckrYbofQ2/uee8JDevWCJUty4y1JUiRMuiVJkvSL0tLg2mtDPbSrr4aSJcP49u1w001Qt25Iwnfu3IeHHHkkvPQSLF8e2oqVKBHGf/ghNBBv1iy0IXvnnb3oZyZJ0TLpliRJ0m+qUAHuvDPsfPftG+8E9sUX4bh5gwbh+PkPP+zDQ+rXh0cfhbVr4frroXz5+Nwbb8Bf/gKtWsHzz+/jgyQp75h0S5Ik6XerVg1GjICPPoIePeLj69eHQmtNmoTCa/u0IV25MtxyS/ihDzwABx0Un5s/H7p3D1n+Qw/Bjh378CBJSjyTbkmSJP1h9erBs8/CwoXQpUt8fPny0GKsVavQcmyfku+0NLjkEvjkE3juOWjRIj63enWYO+gguPHGfajsJkmJZdItSZKkvda8Obz6KkyfDm3bxsfnz4fjjw8nwmfP3seHFC0adrfnz4e33oLjjovPffkl3Hwz1KwJF18cEnRJykdMuiVJkrTP2rYNhcgnTQqJeLapU6F1a+jWLXQJ2yexGHToAP/5T9hi79kz9DiDUMltxAho2DBstc+du48Pk6TcYdItSZKkXBGLwQknwIIF4TR4vXrxuVdeCUXIe/UKJ8P3WfPm8PTToaz6ZZeFo+gQGoqPGwdHHAHt2oVPATIzc+GBkrR3TLolSZKUq1JSwmnwDz+EkSND8TUI97ufeipsRvfvD5s25cLDatYMPb3Xr4fbbgtF2LJNmwZ//WvI9p94Ar7/PhceKEl/jEm3JEmSEqJYMejTJ1yzHj48tB0D2L0bHn449Pi+7jr45ptceFj58jB4MKxZA6NHh+rm2T74AM45B+rUgbvugq1bc+GBkvT7mHRLkiQpoVJT4aqrwknw66+PnwT/9tuwOV2nTugB/u23ufCwkiVD77KPPoIJE+Coo+Jzn30GV18ddsevvjr8WpISzKRbkiRJeaJs2dB+e+XK0O2rWLEw/vXXcM014Q74o4+GnfB9lpICXbvCzJnhq1u3cOkcID097HjXrh12wD/4IBceKEk/z6RbkiRJeapyZXjgAfj4Y+jdO+THABs3wkUXQaNGoQd4rtU/O+ooGD8+7H5fcAEULx7Gd+8Od72bNAl3v6dN28fG4pL0UybdkiRJikStWiHnXbIETj45Pr5yZegG1qJF6AGea3lww4YwahSsXQvXXgvlysXnJk0K1c6PPDJUP8/IyKWHSirsTLolSZIUqUMOgZdfhtmz4S9/iY8vXgwnnghHHw3Tp+fiA6tUgVtvhXXr4N57oUaN+NzcuaHPd8OGYTt+27ZcfLCkwsikW5IkSfnCEUfAlCkweTK0bBkfnzkTjjkm9ABfuDAXH1i6NAwcGLbWn346tBbLtnIlDBgQEvIrrwy745K0F0y6JUmSlK907Bg2nF96Kdzvzvb66+HIeffusGJFLj6wWLFwnn3hQvjPf0IA2bZuhbvvDv3NzjgDZs3KxQdLKgxMuiVJkpTvxGJwyinhiPljj4UuX9mefz4k4xdemMtdv2IxOO64sNW+aFGobJ5ddC0jA158MRRlO/LIEMQPP+TiwyUVVCbdkiRJyreKFg2578cfw333wQEHhPGMjFATrV690AP8yy9z+cHNmoVsf906uPHG+IMB5swJ2+116oTWY998k8sPl1SQmHRLkiQp3ytRIlyxXrkSbropXMcG2LkT/vGPkP8OGwbbt+fygytXhqFDQ/I9Zgw0bRqfW78err4aqlcPjcc/+SSXHy6pIDDpliRJUtIoXRpuuAFWrYIrrgjJOEB6OgwZEq5eP/AA7NqVyw8uWRLOPTccO588OVR1y7ZjBzz0EDRoAF27wtSp9vuWtIdJtyRJkpLO/vuHHe5PPoELLoAiRcL45s1hR7xhw9ADPNfbbcdiodDapEmwbBlcdBGkpoa5rCyYOBHat4fDD4d//Qu+/z6XA5CUbEy6JUmSlLSqVw93uz/8MBQXz7Z2bbgL3rQpjB+foI3nhg3hkUfg00/h9tvhwAPjc++/D717w0EHhXPvX3yRgAAkJQOTbkmSJCW9Bg1CQfH586FTp/j4Rx+FKuhHHhl6gCdEhQpwzTWwejU880zOJuObNoVz7zVqQJ8+4dMBSYWKSbckSZIKjMMOC/28p00L3b2yzZ0bToV37Ajz5iXo4cWKwd//Hh42fXrI9lP+99ftnTth9Gho3Dh8KvCf/3jvWyokTLolSZJU4BxzDMyYAf/+d86C41OmwJ/+FPLhhG06x2LQti289FK4dD5wYLzcOoSEu1MnaNIkJOLffZegQCTlBybdkiRJKpBiMfjrX2HhQnj66dBWLNv48SEZP+eccP87YWrXhnvvDfe+77kHatWKz334YThyXrNmOIK+aVMCA5EUFZNuSZIkFWgpKdCzZ7jf/fDDUKVKGM/MDBXOGzQIFc83b05gEGXKwGWXwYoVMG4ctGkTn/vii1BsrWbNUHxt4cIEBiIpr5l0S5IkqVAoXhwuvjic+L79dihXLox//33o7V2nTugBvnVrAoMoWhROPTWcfZ87F3r0CGMAu3eHNmMtWoS2YxMnhk8GJCU1k25JkiQVKmlpodj4qlUweDCUKhXGd+yAW24Jyfc//gHffpvgQFq1gmefDVXPBw2C8uXjc1OnQteuoS3ZQw/B9u0JDkZSoph0S5IkqVAqXx5uuw1WroR+/ULxcYCvvoKrroK6dcMO+M6dCQ6kenW44w5Yvz6cf69fPz73ySdwySWh5djVV4fXSEoqJt2SJEkq1KpUCZvJy5bBmWeGAmwQ6poNGBBy4EcfDcfQEyotLZx/X7YslF3/y1/ic998A3fdFQqzde8Oc+YkOBhJucWkW5IkSSIcK3/qKVi8OFy7zvbpp3DRRaHg2pgx4ep1QqWkhLLrU6aEompnnx0upANkZMDzz8ORR4ZG5C++CD/8kOCAJO0Lk25JkiTpR5o0CQXGFyyAE0+Mj69dC+efD40aheQ8IyMPgmneHB5/PDz8hhvggAPic7NmwRlnQL16cPfdCa4AJ2lvmXRLkiRJP6NFi1BAfO5c6NQpPr5yJfTqBY0bw9ixeVRgvEoVuOkmWLcO/vnP8MlAtrVr4corw93wAQNCgJLyDZNuSZIk6Ve0agWvvw4zZ0KHDvHx5ctDx69mzeCll/Io+S5ZEs47L5yBnzwZTjghPrd9e6j8Vr8+nHwyvPsuZGXlQVCSfo1JtyRJkvQ7HHUUvPVW6OZ19NHx8Q8+gNNOg8MPD/XP8iTPjcWgY0eYNAk++gj69oXU1DCXlQUTJsCf/wwtW8LTT+dBFThJv8SkW5IkSfoD/vxnmDYN3nwTjjgiPr5wIZx0Uhh744083GQ++GAYMSK0E7vtNqhWLT63YAGcdRbUqhXmvvwyj4KSlC3fJN133HEHsViMgQMH/uJr2rVrRywW+8lXly5d9rzm7LPP/sl8px9fwpEkSZL2USwGxx4baplNmhR2ubPNmwedO0PbtvD223kYVMWKMHgwrF4ddrd/HNTGjXDddaHfd9++oS2ZpDyRL5LuefPmMXLkSJo1a/arr3v55ZfZuHHjnq+lS5dSpEgRTj/99Byv69SpU47XPffcc4kMX5IkSYVULBauVc+bB+PHh/vd2d57L9wBb98epk/Pw6CKF4eePUNQ774b7ndnNx//7jsYOTKUYD/hhHAv3HvfUkJFnnRv376dnj17Mnr0aMqXL/+rr61QoQJVqlTZ8zV58mRKlSr1k6S7RIkSOV73Wz9XkiRJ2hexGHTrBu+/Dy+8EHLabFOnwjHHwHHHwezZeRzU0UfDyy/DJ5+Eyub77Reff/31EFSzZqEB+c6deRicVHhEnnT369ePLl260LFjxz/8vWPGjKF79+6kpaXlGJ86dSqVKlWiYcOGXHTRRXzp3RVJkiTlgZQUOP10WLIEnnkmFBLPNnkytG4NXbrA/Pl5HFidOnDfffDpp6Gn90EHxeeWLg0NyGvWhBtvhM8/z+PgpIKtaJQPHzt2LAsWLGDevHl/+Hvnzp3L0qVLGTNmTI7xTp06ccopp1C7dm1WrlzJtddeS+fOnZk1axZFihT52Z+1a9cudu3atefX6enpAGRmZpKZJ70flGiZmZlkZWX5+6lc5bpSIriulCiurbwVi0H37qGq+dNPw7BhMVavDke8X3stfHXtmsXQoVn8xg3L3FW6NAwcCP37w4QJxO6/n9h774W5LVvg5pvJuuMO6NGDrAEDoHnzX/1xrislSjKsrd8bWywrK5pLHOvXr6dly5ZMnjx5z13udu3aceihh3Lffff95vdfeOGFzJo1i8WLF//q61atWkXdunV566236PDjxoo/MnToUG666aafjH/88ceULl36t9+M8r3MzEy2bt1K2bJlSUmJ/ICHCgjXlRLBdaVEcW1Fa/dueP75VO69dz82bMi5EXTiid9xxRXbadgwI5LYir3/PqVGjaLkv/9NLCNnDLvatuXbPn3Y1aFD2Mb/f1xXSpRkWFvbtm2jQYMGbN26lTJlyvzi6yJLuidMmMDJJ5+cY/c5IyODWCxGSkoKu3bt+sWd6R07dlCtWjVuvvlmBgwY8JvPOuCAAxg2bBgXXnjhz87/3E53jRo1+Prrr3/1X56SR2ZmJlu2bOGAAw7It39olXxcV0oE15USxbWVP+zaFa5P33ZbjI0bY3vGY7EsevSAIUOyaNAgouDWryf28MMwejSxb77JMZXVoAFZl14KvXrBj652uq6UKMmwttLT0ylfvnz+Tbq3bdvG2rVrc4ydc845HHzwwQwaNIgmTZr84vc+8cQT9O3bl88++4yKFSv+6nM+/fRTatasyYQJEzjppJN+V2zp6emULVv2N//lKXlkZmayefNmKlWqlG//0Cr5uK6UCK4rJYprK3/JLiJ+++2weXN8vEiR0FZ7yJBwDTsS27fDk0+GO+CffJJzrnx56NMnHE+vXt11pYRJhrX1e/PGyKIvXbo0TZo0yfGVlpZGxYoV9yTcvXr1YvDgwT/53jFjxtCtW7efJNzbt2/nqquuYvbs2axZs4YpU6bQtWtX6tWrx/HHH58n70uSJEn6Lamp4Wr1qlUwfHhosQ2QkQFPPAENG4bcdt26CILbbz/o1w+WL4eJE0PPs2xffw133gm1akGPHjB3bgQBSsklf35k8D/r1q1j48aNOcaWL1/OjBkzOO+8837y+iJFirB48WJOOukkGjRowHnnncfhhx/O9OnTKVGiRF6FLUmSJP0uaWlw1VWwejUMGwblyoXxH36A0aND9fP+/WHDhgiCS0mBE0+Et98OvdB694ZixcJcRgaMHUtK69ZUOOkkeP75cHFd0k9Edrw8P/N4ecGTDMdTlHxcV0oE15USxbWVHL75Jpzqvvde+F9DHQBKloS+feGaa6By5aiiAzZtgkcegREj4Isvcs5VrRqC7NMHqlSJJj4VGMnw36x8f7xckiRJUk7lysHQoWHne/DgeM2ynTtDMl6nDgwa9NN8N89UqQI33xzOvY8eTVbjxvG5jRtDn++aNaFnT5g1C9zfk0y6JUmSpPymQgW47baQfF95ZbgDDvDtt+EOeO3acP314Yp1JFJT4fzzyVq0iK9efJGsbt3iLcV274Znn4WjjoKWLeHxx0PlOKmQMumWJEmS8qkDDoC77oKVK+HSSyG7TNH27XDrrSH5vvlm2Lo1ogBjMb5v25asl14KnxBcc028KhzAggVw7rlQo0aY+3/di6TCwKRbkiRJyueqVoX77w8dvC66KF7PbOvWcKK7du3Qfmz79giDrFkzBPHpp6EE++GHx+e+/DJUPa9TB04+GaZM8ei5Cg2TbkmSJClJVK8e6ph9/DGcd17o6w3hmPm114bk+x//CMfQI1OyZKh0Pm9euNfds2f8U4LMTJgwATp2hMaN4eGHYdu2CIOVEs+kW5IkSUoytWrBP/8ZWmn36hW/Tv3FF6EFWd268MADoQBbZGIxOPJIePppWL8ebrkFqlWLz3/0UeiHduCB4ez88uXRxSolkEm3JEmSlKTq1oUnn4QPPoAePUKeC6Gz14ABUK9e6O71/ffRxknlyqHy25o18MILcMwx8blt2+DBB+Hgg+G44+Df/w59wKUCwqRbkiRJSnIHHxwKhi9eDKeeGh//7DO4+GJo0ADGjAmFxSNVrBicfjpMmwYLF8IFF8RLswNMngwnnRQ+LbjrLvjqq8hClXKLSbckSZJUQDRpAuPGhaLhJ50UH1+7Fs4/Hxo1gn/9K59sJDdvDqNGhU8G7r47FFnLtmYNXH11OHp+/vkhQZeSlEm3JEmSVMC0aAGvvAJz50KnTvHxlStDjbPGjWHs2FDXLHLly8Pll4fqcK++mjPgnTvDFn2LFtC2LTz/fD7Yrpf+GJNuSZIkqYBq1Qpefx1mzoQOHeLjy5eHO+DNmsFLL+WT5LtIEejSJQS8fHm4lF6mTHx+5kzo3h0OOghuuilcXJeSgEm3JEmSVMAddRS89RZMnQpHHx0f/+ADOO200FJ74sR81Dq7QQO4775w9HzEiLA1n23jRhg6NPQF//vf4b338lHg0k+ZdEuSJEmFxJ//HGqYTZ4cunllW7gQunaFI46AN97IRznsfvtB376wZAm8/Tacckq8P9ru3fDcc9CmDbRsCY8/Dt99F2280s8w6ZYkSZIKkVgMOnYMG8STJoVd7mzz5kHnzuH69JQp+Sj5jsWgfftwFn71ahg8GPbfPz6/YAGcey5Urw6DBoVCbFI+YdItSZIkFUKxGJxwQki0J0wI97uzvfdeSMzbt4fp0yML8efVrAm33Qbr14cm5S1bxue++gqGDw8NzLt1C2fq880nByqsTLolSZKkQiwWC0fL338fXnghtBXLNm0aHHMMHHcczJ4dXYw/q2RJ6NUrlGifPRvOPDP0AYdQGe6VV+DYY+GQQ+Dhh2HbtmjjVaFl0i1JkiSJlBQ4/fRwffqZZ6B+/fjc5MnQunUoLj5/fnQx/qxYLFxGf+qpsPt9yy2hv3e2Zcugf/8wdskloTK6lIdMuiVJkiTtUaRIKAr+4YfwxBNQu3Z87rXXwmnubt1g8eKoIvwVlSvD9deHe98vvhi26bNt2wYPPQQHHxy27idOhIyM6GJVoWHSLUmSJOknihaF3r3DxvCoUVCjRnzulVegeXP4299iLF9eJLogf0mxYqEX2rRpsGgR9OkDqanx+cmTw5n6evXgrrvgyy+ji1UFnkm3JEmSpF9UrBhccAGsWBGuRlerFp8bNy5G+/b706NHjKVLo4vxVzVrBiNHhp7fd98NderE59asgauvDlXPzzsvXGyXcplJtyRJkqTfVKIEXHwxfPIJ3HsvVKoUxrOyYrzwQoymTcPm8qJF0cb5i8qXh8svD58eTJoUeqNl27kTHnsMDjss9EsbOxa+/z66WFWgmHRLkiRJ+t1SU2HgQFi1Cu68M5OKFeP3ol96CQ49NNz5zncF17KlpIReaa+9Bh9/HN5MmTLx+ZkzoUcPqFULbroJNm6MKlIVECbdkiRJkv6wtDS48kqYO/cL7r47kypV4nOvvBIKrv31r6GjV75Vv37Ytv/sMxgxAho3js9t3AhDh4a+4D16hGTcnt/aCybdkiRJkvZaqVJZe3a+H3gg553vSZNCN69OneC99yIL8bfttx/07Rv6pb3zDpx6aijjDvDDD+G4edu2cPjh4Rj6d99FG6+Sikm3JEmSpH2WmhraYK9cCY88krPa+X/+A23aQMeO8O670cX4m2IxaNcOxo0LbceuvRb23z8+//77oeBa9eowaFAoxCb9BpNuSZIkSbmmZEm46KJQcG3UqHA1OtuUKfDnP4e89u238/lp7Ro14NZbYf16ePLJcF4+21dfwfDhoRJ6166hBVm+fjOKkkm3JEmSpFxXvHhoNfbxx+FEdt268blp06BDBzj6aHjzzXyer5YsCb16wbx5MGcOnHlmeHMQAp84EY47Dho1gocegvT0aONVvmPSLUmSJClhihWDc86BZcvgX/+CBg3iczNnwvHHQ+vWoZh4vk6+Af70J3jqKVi3DoYNgwMPjM8tXx7O1x94YPjfZcuii1P5ikm3JEmSpIQrWhTOOgs+/BCefTZsDGebMwe6dIFWrcLGcb5PvitXhuuuC3e6x40LZ+azbd8edrwbNYJjjw2l3DMyfvFHqeAz6ZYkSZKUZ4oUCR24li6FF16Apk3jc/PnhyvSLVqEnt+ZmdHF+bsULRoqnU+dCosXw4UXQqlS8fm33gpNy+vWDXfAv/wyqkgVIZNuSZIkSXkuJQVOPx0WLoSXX4ZDD43PLVoEp50GzZrB888nyUZx06bw6KPw6adwzz05L7GvXRuqnVevDmefDbNmJcF2vnKLSbckSZKkyKSkwMknw4IF4Wj5j4uEf/ABdO8OTZrAM8+Eltn5XvnycNlloYLcpEnQuXN8bufOUAn9qKOgefPQW23r1uhiVZ4w6ZYkSZIUuVgMTjwR5s6F11+HI4+Mzy1bFoqGH3JIyFmTIvlOSYETTggV4lasgIEDoVy5+PySJdCvH1SrBuefD//9b1SRKsFMuiVJkiTlG7EYdOoE770X2l+3bRufW7EinM5u2BDGjIHvv48szD+mXj2491747DN44olQrj3bt9+GN9OqFRx+eGhuvn17ZKEq95l0S5IkScp3YjHo2BHefRfeeQfat4/PrVoVNocbNICRI2HXruji/ENKlYLevcMnCosWwcUXQ+nS8fkFC0IxtmrV4KKLwoV3JT2TbkmSJEn5ViwG7drB22+HBPzYY+Nza9dC375hI/nhh8OV6aTRrFkIesMGGD0652X2bdtCUbYWLcI5+8cfDzviSkom3ZIkSZKSwtFHw5tvho3iH9cn+/RT6N8f6tSB++9Psvx0v/3Ctv28eeFe9wUXQFpafH7OHDj33LD7femlobqckopJtyRJkqSk0rp1qE82d24ovpZt48ZQr6xOHbj7btixI7IQ9072ne4NG2DEiFDhPNvWrfDgg6GUe9u28PTTSba1X3iZdEuSJElKSq1ahTZjCxaEtmPZPv8crrwSatWCO+8Mp7WTSpky4dz8++/D7Nmhelxqanx+5kw46yw48EC4/HJYvjyyUPXbTLolSZIkJbUWLeDll0NtstNPD/fAAb74Aq65JiTft96ahC2xYzE44ohwp3vDBnjgAWjcOD7/1VehKvrBB4dKc2PHJlFVucLDpFuSJElSgdCsGbzwQmiB3aNHaJUNITe9/vqQfA8dCl9/HWWUe6lcObjkkvDmpk8PjctLlIjPT50a3nSNGjBoEKxcGVWk+n9MuiVJkiQVKI0bw7PPwocfQq9e8eT7m2/gpptC8j1kCHz5ZZRR7qVYLNzpfuqp0Pf77rtD77RsW7bA8OGhpPtxx8FLL8Hu3dHFK5NuSZIkSQVTw4bw5JPhyvM550CRImE8PR2GDQvJ9+DBIU9NShUrhjvdy5aFZuZ/+xsUKxafnzwZTjsNatYMW/1r10YXayFm0i1JkiSpQKtXDx57DFasgD594nnp9u1wxx0h+b7ySti0KdIw9152M/OxY0P/tDvvDCXcs23aFC61164NJ5wQqs/98ENk4RY2Jt2SJEmSCoXatWHkSPjkE7j4YihePIx/+204pV27dmg5tmFDpGHum0qV4OqrwycMb74Jp54a3+LPyoLXX4euXeMX3D/9NMpoCwWTbkmSJEmFSs2a8PDDsGoVXHoplCwZxnfuhPvvD5vE/fvD+vXRxrlPUlLg2GNh3LjwRoYNg4MOis9/9lm44H7QQSEJf/11yMiILt4CzKRbkiRJUqF04IEhyV61KlyNzm6FvWtXSMrr1g3tstesiTTMfVe1Klx3XahoPmkSnHRSvLpcZmY4bn7CCeEN33orbNwYbbwFjEm3JEmSpEKtatVwvHzNmnAyOy0tjO/eHY6j168P559fALpwFSkSkutXXglv9sYbwycP2dauDQXXatYMBdgmTw5JufaJSbckSZIkEa5D33lnyEevvRZKlw7jP/wAY8aEauhnnw0ffxxllLmkRo1wp3vNmpCEd+4cCrJBeMMvvRRajjVoEFqQbd4cZbRJzaRbkiRJkn5k//3DKes1a+CGG6Bs2TCekRFakDVqBGeeCR99FGmYuaNo0XDc/LXXwjn7666DKlXi8ytXwqBBUL06dO8OU6eGgmz63Uy6JUmSJOlnVKgQao2tWQM33wzly4fxzEx45hlo3DjkoUuXRhpm7qlVKxRcW7cuFGA79tj43O7d8Pzz0L59+NThnnvgyy8jCzWZmHRLkiRJ0q8oVw6GDAnJ9223QcWKYTwrK+ShTZuGK9ALF0YYZG4qViy0GnvzzdB67Oqr4YAD4vPLl8MVV4T74GedBTNmuPv9K0y6JUmSJOl3KFMGBg8Oyffw4eEOeLaXXoIWLaBbN5g/P6oIE6BevXDRff16GDsW2rWLz+3aBU8/DUcfHT55ePBB+OabqCLNt0y6JUmSJOkP2G8/uOoqWL0a7r035xXoV16Bli3hr3+FOXOiizHXlSgBf/sbvPNOuMx+2WXh/H22Dz4ITc+rVYNzzw1v3t1vwKRbkiRJkvZKqVIwcGCoP/bggzm7b02aBEceCccfDzNnRhZiYhx8cLjT/dln8NRT0KZNfO677+Dxx8Obb9ECHn0Utm2LLtZ8wKRbkiRJkvZBair07x8KfY8YEdpcZ3vzTWjbFjp0gGnToosxIUqWDGXcZ8yAJUvgkkvipd4BFi2Ciy4KjdD79Clg5+5/P5NuSZIkScoFJUpA376h9tjo0VC7dnzu7bfDdei2bcMueIE7ed2kCTzwAGzYAI89BkccEZ/bsSP8C2nZElq1gn/+M4wVEibdkiRJkpSLiheH888PRb4ffzzUIss2c2a4733oofDcc/DDD5GFmRilSsE558Ds2fD+++FTiP32i8//979wwQXh7ne/frB4cXSx5hGTbkmSJElKgGLF4OyzQ92xp54K7a2zLV4Mf/87NGwII0fCzp2RhZk4hx4azttv2BDe5GGHxefS0+GRR6B5czjqKHjyyXAfvAAy6ZYkSZKkBCpaNFx9XroUxo+HP/0pPrdqVdgMrl0b7rqrgNYcK106fqd73jw477ywI55t1qzw6US1aqEy3UcfRRVpQph0S5IkSVIeSEkJfbxnz4YpU6Bjx/jcpk1w9dWhCNuQIbBlS2RhJlbLluFO94YN8PDDob93tm++gfvvh0MOIdauHSVffjn0Ak9yJt2SJEmSlIdiMfjLX2Dy5LDxe+qpYQxC3jlsGBx0EAwYAOvWRRpq4pQtCxdfHCqcv/ce9O4dqqH/T2z6dMr16xfmkly+SbrvuOMOYrEYAwcO/MXXtGvXjlgs9pOvLl267HlNVlYWN9xwA1WrViU1NZWOHTuyYsWKPHgHkiRJkvTHtGwJ48bBhx+G+mNFi4bx774LxcDr1o3fCy+QYjFo3RqeeCLsft93357L7z/UrRtKvie5fJF0z5s3j5EjR9KsWbNffd3LL7/Mxo0b93wtXbqUIkWKcPrpp+95zfDhw3nggQd49NFHmTNnDmlpaRx//PHsLJCVCSRJkiQVBAcfHDptrVoVdrizrzz/8EOoMda4MZxyStgZL7DKlw9v/oMPyHznHdJvuil+BCCJRZ50b9++nZ49ezJ69GjKly//q6+tUKECVapU2fM1efJkSpUqtSfpzsrK4r777uP666+na9euNGvWjH/9619s2LCBCRMm5MG7kSRJkqS9V6NG2Oxduzbc7S5XLoxnZcWLsHXsGO6EF7he39liMTjmGL7v0CHqSHJF0agD6NevH126dKFjx44MGzbsD33vmDFj6N69O2lpaQCsXr2aTZs20fFHFQnKli3LEUccwaxZs+jevfvP/pxdu3ax60cX9NPT0wHIzMwkMzPzj74l5UOZmZlkZWX5+6lc5bpSIriulCiuLSWC6ypxKlSAoUPhiitg1Ci4994YGzeGXd8pU8JXq1ZZDBqURdeuoUhbQZIMa+v3xhZp0j127FgWLFjAvL04IzF37lyWLl3KmDFj9oxt2rQJgMqVK+d4beXKlffM/Zzbb7+dm2666SfjW7Zs8Vh6AZGZmcnWrVvJysoipaD9F0mRcV0pEVxXShTXlhLBdZU3zjoLTj8dXnwxlUceSWPNmpDGzZsX47TTYtSv/wP9+2/n5JN3UqxYxMHmkmRYW9t+Z3+3yJLu9evXM2DAACZPnkzJH1Wp+73GjBlD06ZN+dOPm9ztpcGDB3P55Zfv+XV6ejo1atTggAMOoEyZMvv88xW9zMxMYrEYBxxwQL79Q6vk47pSIriulCiuLSWC6ypvXXFFuPI8blwmw4fHWLQo7HyvWFGUAQPKcffdWVxxRRbnnpuzDXYySoa19Xvz2MiS7vnz57N582YOO+ywPWMZGRm8++67PPTQQ+zatYsiRYr87Pfu2LGDsWPHcvPNN+cYr1KlCgCff/45VatW3TP++eefc+ihh/5iLCVKlKBEiRI/GU9JScm3v8H642KxmL+nynWuKyWC60qJ4tpSIriu8lbx4vD3v0OPHvD663D77TBjRphbty7GgAExhg0LyXm/fvE74ckov6+t3xtXZNF36NCBJUuWsHDhwj1fLVu2pGfPnixcuPAXE26AF198kV27dnHmmWfmGK9duzZVqlRhypQpe8bS09OZM2cOrVu3Tth7kSRJkqS8FIvBCSfA9Onh60ddlNmyBa6/HmrWhEGDYOPG6OJUhEl36dKladKkSY6vtLQ0KlasSJMmTQDo1asXgwcP/sn3jhkzhm7dulGxYsUc49l9vocNG8bEiRNZsmQJvXr1olq1anTr1i0v3pYkSZIk5am2beHVV2HRorADnr0Bu20bDB8OtWtD376hHZnyXv7cp/+fdevWsfH/fSyzfPlyZsyYwXnnnfez33P11VdzySWX0KdPH1q1asX27dt544039ureuCRJkiQli2bN4Nln4eOP4cILw1F0gF27YORIqF8/HE1fvDjaOAubWFZWge3uttfS09MpW7YsW7dutZBaAZGZmcnmzZupVKlSvr0TouTjulIiuK6UKK4tJYLrKn/buBHuvRdGjIDt23POdekCgwdDmzbRxPZbkmFt/d68MX9GL0mSJEnaJ1WrhuPl69bBLbfA/vvH5yZNCsfSjzkmFGRzKzZxTLolSZIkqQArXz4UVlu7Fu6/H2rUiM9Nnx4Ksh12GDz/PGRkRBdnQWXSLUmSJEmFQKlScOmlsHIlPPEEHHxwfG7hQujeHRo2hFGjwj1w5Q6TbkmSJEkqRIoVg9694YMP4OWXoVWr+NzKlaEIW+3a8I9/hAro2jcm3ZIkSZJUCKWkwMknw5w58NZb0KFDfG7jRrjqKjjoILjhBvjii+jiTHYm3ZIkSZJUiMViIeF+6y2YOzck4tm+/joUYTvoIBg4ENavjyzMpGXSLUmSJEkCwlHzl1+GDz8MR9CLFg3j334birDVrQvnngvLl0cbZzIx6ZYkSZIk5dCoUSi2tnJlKL6WmhrGd++Gxx8P86edBvPnRxpmUjDpliRJkiT9rJo1ww732rWh7Vi5cmE8KwteeglatoRjj4W337bX9y8x6ZYkSZIk/aoDDgh3u9euheHDoUqV+Fx2EbYjj4QJEyAzM7Iw8yWTbkmSJEnS71KmTKhqvno1PPoo1KkTn8suwta0KfzrX+Eouky6JUmSJEl/UMmSoZ/38uXw7LPQrFl8LrsIW/368NBDoQhbYWbSLUmSJEnaK0WLQo8esHAhvPoqtGkTn1u7Fi65BGrVgttug2++iSjIiJl0S5IkSZL2SSwGXbrAjBkwfTqccEJ8bssWuO66UJRt0CDYtCm6OKNg0i1JkiRJyjVt28KkSWH3u3t3SPlf1rltWyjCVqsWXHQRrFoVZZR5x6RbkiRJkpTrmjeH554L97779IHixcP4rl2hCFuDBtCzJyxZEm2ciWbSLUmSJElKmHr1YOTIUPH8yithv/3CeEZGvAjbiSfCe+9FG2eimHRLkiRJkhKuWjW4665QYO3mm6FixfhcdhG2P/8Z3ngDsrKiizO3mXRLkiRJkvJMhQowZEhIvu+7D6pXj8+9+y507gytWsWYOLEkGRmRhZlrTLolSZIkSXkuLQ0GDICVK+Gxx6Bhw/jc++/HuPDCcrzxRnTx5RaTbkmSJElSZIoXh3POgQ8+gHHj4PDDw3j9+j/QuXO0seWGolEHIEmSJElSkSJw6qlwyikweXImX32VTkpKuajD2mcm3ZIkSZKkfCMWg44dYfPm76MOJVd4vFySJEmSpAQx6ZYkSZIkKUFMuiVJkiRJShCTbkmSJEmSEsSkW5IkSZKkBDHpliRJkiQpQUy6JUmSJElKEJNuSZIkSZISxKRbkiRJkqQEMemWJEmSJClBTLolSZIkSUoQk25JkiRJkhLEpFuSJEmSpAQx6ZYkSZIkKUFMuiVJkiRJShCTbkmSJEmSEsSkW5IkSZKkBDHpliRJkiQpQUy6JUmSJElKkKJRB5AfZWVlAZCenh5xJMotmZmZbNu2jZIlS5KS4mdNyh2uKyWC60qJ4tpSIriulCjJsLay88Xs/PGXmHT/jG3btgFQo0aNiCORJEmSJOVn27Zto2zZsr84H8v6rbS8EMrMzGTDhg2ULl2aWCwWdTjKBenp6dSoUYP169dTpkyZqMNRAeG6UiK4rpQori0lgutKiZIMaysrK4tt27ZRrVq1X92Nd6f7Z6SkpFC9evWow1AClClTJt/+oVXycl0pEVxXShTXlhLBdaVEye9r69d2uLPlz8PxkiRJkiQVACbdkiRJkiQliEm3CoUSJUpw4403UqJEiahDUQHiulIiuK6UKK4tJYLrSolSkNaWhdQkSZIkSUoQd7olSZIkSUoQk25JkiRJkhLEpFuSJEmSpAQx6VaBdfvtt9OqVStKly5NpUqV6NatG8uXL486LBUwd9xxB7FYjIEDB0YdigqAzz77jDPPPJOKFSuSmppK06ZN+e9//xt1WEpiGRkZDBkyhNq1a5OamkrdunW55ZZbsKSP/qh3332XE088kWrVqhGLxZgwYUKO+aysLG644QaqVq1KamoqHTt2ZMWKFdEEq6Txa+tq9+7dDBo0iKZNm5KWlka1atXo1asXGzZsiC7gvWTSrQJr2rRp9OvXj9mzZzN58mR2797Ncccdx44dO6IOTQXEvHnzGDlyJM2aNYs6FBUAX3/9NW3atKFYsWK8/vrrfPjhh9x9992UL18+6tCUxO68805GjBjBQw89xEcffcSdd97J8OHDefDBB6MOTUlmx44dNG/enIcffvhn54cPH84DDzzAo48+ypw5c0hLS+P4449n586deRypksmvratvv/2WBQsWMGTIEBYsWMDLL7/M8uXLOemkkyKIdN9YvVyFxpYtW6hUqRLTpk3jmGOOiTocJbnt27dz2GGH8cgjjzBs2DAOPfRQ7rvvvqjDUhK75pprmDlzJtOnT486FBUgf/3rX6lcuTJjxozZM3bqqaeSmprK008/HWFkSmaxWIzx48fTrVs3IOxyV6tWjSuuuIIrr7wSgK1bt1K5cmWeeOIJunfvHmG0Shb/f139nHnz5vGnP/2JtWvXUrNmzbwLbh+5061CY+vWrQBUqFAh4khUEPTr148uXbrQsWPHqENRATFx4kRatmzJ6aefTqVKlWjRogWjR4+OOiwluaOOOoopU6bw8ccfA7Bo0SJmzJhB586dI45MBcnq1avZtGlTjv9PLFu2LEcccQSzZs2KMDIVNFu3biUWi1GuXLmoQ/lDikYdgJQXMjMzGThwIG3atKFJkyZRh6MkN3bsWBYsWMC8efOiDkUFyKpVqxgxYgSXX3451157LfPmzePSSy+lePHi9O7dO+rwlKSuueYa0tPTOfjggylSpAgZGRnceuut9OzZM+rQVIBs2rQJgMqVK+cYr1y58p45aV/t3LmTQYMG0aNHD8qUKRN1OH+ISbcKhX79+rF06VJmzJgRdShKcuvXr2fAgAFMnjyZkiVLRh2OCpDMzExatmzJbbfdBkCLFi1YunQpjz76qEm39toLL7zAM888w7PPPkvjxo1ZuHAhAwcOpFq1aq4rSUlj9+7dnHHGGWRlZTFixIiow/nDPF6uAq9///68+uqrvPPOO1SvXj3qcJTk5s+fz+bNmznssMMoWrQoRYsWZdq0aTzwwAMULVqUjIyMqENUkqpatSqHHHJIjrFGjRqxbt26iCJSQXDVVVdxzTXX0L17d5o2bcpZZ53FZZddxu233x51aCpAqlSpAsDnn3+eY/zzzz/fMyftreyEe+3atUyePDnpdrnBpFsFWFZWFv3792f8+PG8/fbb1K5dO+qQVAB06NCBJUuWsHDhwj1fLVu2pGfPnixcuJAiRYpEHaKSVJs2bX7S1vDjjz/moIMOiigiFQTffvstKSk5/7pXpEgRMjMzI4pIBVHt2rWpUqUKU6ZM2TOWnp7OnDlzaN26dYSRKdllJ9wrVqzgrbfeomLFilGHtFc8Xq4Cq1+/fjz77LO88sorlC5des+dorJly5KamhpxdEpWpUuX/kldgLS0NCpWrGi9AO2Tyy67jKOOOorbbruNM844g7lz5zJq1ChGjRoVdWhKYieeeCK33norNWvWpHHjxrz//vvcc889nHvuuVGHpiSzfft2Pvnkkz2/Xr16NQsXLqRChQrUrFmTgQMHMmzYMOrXr0/t2rUZMmQI1apV+9VK1NKvrauqVaty2mmnsWDBAl599VUyMjL2/H2+QoUKFC9ePKqw/zBbhqnAisViPzv++OOPc/bZZ+dtMCrQ2rVrZ8sw5YpXX32VwYMHs2LFCmrXrs3ll1/OBRdcEHVYSmLbtm1jyJAhjB8/ns2bN1OtWjV69OjBDTfckFR/YVX0pk6dSvv27X8y3rt3b5544gmysrK48cYbGTVqFN988w1t27blkUceoUGDBhFEq2Txa+tq6NChv3hS9Z133qFdu3YJji73mHRLkiRJkpQg3umWJEmSJClBTLolSZIkSUoQk25JkiRJkhLEpFuSJEmSpAQx6ZYkSZIkKUFMuiVJkiRJShCTbkmSJEmSEsSkW5IkSZKkBDHpliRJCROLxZgwYULUYUiSFBmTbkmSCqizzz6bWCz2k69OnTpFHZokSYVG0agDkCRJidOpUycef/zxHGMlSpSIKBpJkgofd7olSSrASpQoQZUqVXJ8lS9fHghHv0eMGEHnzp1JTU2lTp06jBs3Lsf3L1myhL/85S+kpqZSsWJF+vTpw/bt23O85rHHHqNx48aUKFGCqlWr0r9//xzzX3zxBSeffDKlSpWifv36TJw4MbFvWpKkfMSkW5KkQmzIkCGceuqpLFq0iJ49e9K9e3c++ugjAHbs2MHxxx9P+fLlmTdvHi+++CJvvfVWjqR6xIgR9OvXjz59+rBkyRImTpxIvXr1cjzjpptu4owzzmDx4sWccMIJ9OzZk6+++ipP36ckSVGJZWVlZUUdhCRJyn1nn302Tz/9NCVLlswxfu2113LttdcSi8Xo27cvI0aM2DN35JFHcthhh/HII48wevRoBg0axPr160lLSwPgtdde48QTT2TDhg1UrlyZAw88kHPOOYdhw4b9bAyxWIzrr7+eW265BQiJ/H777cfrr7/u3XJJUqHgnW5Jkgqw9u3b50iqASpUqLDnn1u3bp1jrnXr1ixcuBCAjz76iObNm+9JuAHatGlDZmYmy5cvJxaLsWHDBjp06PCrMTRr1mzPP6elpVGmTBk2b968t29JkqSkYtItSVIBlpaW9pPj3rklNTX1d72uWLFiOX4di8XIzMxMREiSJOU73umWJKkQmz179k9+3ahRIwAaNWrEokWL2LFjx575mTNnkpKSQsOGDSldujS1atViypQpeRqzJEnJxJ1uSZIKsF27drFp06YcY0WLFmX//fcH4MUXX6Rly5a0bduWZ555hrlz5zJmzBgAevbsyY033kjv3r0ZOnQoW7Zs4ZJLLuGss86icuXKAAwdOpS+fftSqVIlOnfuzLZt25g5cyaXXHJJ3r5RSZLyKZNuSZIKsDfeeIOqVavmGGvYsCHLli0DQmXxsWPHcvHFF1O1alWee+45DjnkEABKlSrFf/7zHwYMGECrVq0oVaoUp556Kvfcc8+en9W7d2927tzJvffey5VXXsn+++/PaaedlndvUJKkfM7q5ZIkFVKxWIzx48fTrVu3qEORJKnA8k63JEmSJEkJYtItSZIkSVKCeKdbkqRCyhtmkiQlnjvdkiRJkiQliEm3JEmSJEkJYtItSZIkSVKCmHRLkiRJkpQgJt2SJEmSJCWISbckSZIkSQli0i1JkiRJUoKYdEuSJEmSlCAm3ZIkSZIkJcj/ASDO1Y74eHYTAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            " TRAINING COMPLETE!\n",
            "============================================================\n",
            " Final training loss: 4.6817\n",
            " Final validation loss: 4.7031\n",
            " Model trained for 12 epochs\n",
            "\n",
            " Your attention-based seq2seq model is ready!\n",
            "   Try translating new sentences or increase dataset size for better results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simplified transformer"
      ],
      "metadata": {
        "id": "b-BxudtKNg-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"Sinusoidal positional encoding\"\"\"\n",
        "\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() *\n",
        "                           (-math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:x.size(0), :]"
      ],
      "metadata": {
        "id": "S2biD5qkNiqh"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"Multi-head attention with 2 heads as specified\"\"\"\n",
        "\n",
        "    def __init__(self, d_model, num_heads=2):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert d_model % num_heads == 0\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads\n",
        "\n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        attention_weights = F.softmax(scores, dim=-1)\n",
        "        output = torch.matmul(attention_weights, V)\n",
        "\n",
        "        return output, attention_weights\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        batch_size = query.size(0)\n",
        "\n",
        "        # Linear transformations and split into heads\n",
        "        Q = self.W_q(query).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        K = self.W_k(key).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        V = self.W_v(value).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "        # Apply attention\n",
        "        attn_output, attention_weights = self.scaled_dot_product_attention(Q, K, V, mask)\n",
        "\n",
        "        # Concatenate heads\n",
        "        attn_output = attn_output.transpose(1, 2).contiguous().view(\n",
        "            batch_size, -1, self.d_model)\n",
        "\n",
        "        # Final linear transformation\n",
        "        output = self.W_o(attn_output)\n",
        "\n",
        "        return output, attention_weights"
      ],
      "metadata": {
        "id": "0c3RpRRoNj83"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderLayer(nn.Module):\n",
        "    \"\"\"Simplified encoder layer with layer norm and residual connections\"\"\"\n",
        "\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super(TransformerEncoderLayer, self).__init__()\n",
        "\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(d_ff, d_model)\n",
        "        )\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # Self-attention with residual connection\n",
        "        attn_output, _ = self.self_attn(x, x, x, mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "\n",
        "        # Feed-forward with residual connection\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm2(x + self.dropout(ff_output))\n",
        "\n",
        "        return x\n",
        "\n",
        "class TransformerDecoderLayer(nn.Module):\n",
        "    \"\"\"Simplified decoder layer with masked self-attention and cross-attention\"\"\"\n",
        "\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super(TransformerDecoderLayer, self).__init__()\n",
        "\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(d_ff, d_model)\n",
        "        )\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, encoder_output, tgt_mask=None, src_mask=None):\n",
        "        # Masked self-attention\n",
        "        attn_output, _ = self.self_attn(x, x, x, tgt_mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "\n",
        "        # Cross-attention\n",
        "        attn_output, attention_weights = self.cross_attn(x, encoder_output, encoder_output, src_mask)\n",
        "        x = self.norm2(x + self.dropout(attn_output))\n",
        "\n",
        "        # Feed-forward\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm3(x + self.dropout(ff_output))\n",
        "\n",
        "        return x, attention_weights"
      ],
      "metadata": {
        "id": "9jO8s6oDNm8h"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimplifiedTransformer(nn.Module):\n",
        "    \"\"\"Simplified Transformer model for machine translation\"\"\"\n",
        "\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=64, num_heads=2,\n",
        "                 num_encoder_layers=2, num_decoder_layers=2, d_ff=128, max_len=100, dropout=0.1):\n",
        "        super(SimplifiedTransformer, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.src_vocab_size = src_vocab_size\n",
        "        self.tgt_vocab_size = tgt_vocab_size\n",
        "\n",
        "        # Embeddings\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "\n",
        "        # Positional encoding\n",
        "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
        "\n",
        "        # Encoder layers (2 layers as specified)\n",
        "        self.encoder_layers = nn.ModuleList([\n",
        "            TransformerEncoderLayer(d_model, num_heads, d_ff, dropout)\n",
        "            for _ in range(num_encoder_layers)\n",
        "        ])\n",
        "\n",
        "        # Decoder layers (2 layers as specified)\n",
        "        self.decoder_layers = nn.ModuleList([\n",
        "            TransformerDecoderLayer(d_model, num_heads, d_ff, dropout)\n",
        "            for _ in range(num_decoder_layers)\n",
        "        ])\n",
        "\n",
        "        # Output layer\n",
        "        self.output_projection = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Initialize weights\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "\n",
        "    def create_causal_mask(self, size):\n",
        "        \"\"\"Create causal mask for autoregressive generation\"\"\"\n",
        "        mask = torch.tril(torch.ones(size, size))\n",
        "        return mask.unsqueeze(0).unsqueeze(0)  # Add batch and head dimensions\n",
        "\n",
        "    def encode(self, src, src_mask=None):\n",
        "        \"\"\"Encode source sequence\"\"\"\n",
        "        # Embedding + positional encoding\n",
        "        x = self.src_embedding(src) * math.sqrt(self.d_model)\n",
        "        x = self.pos_encoding(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Pass through encoder layers\n",
        "        for layer in self.encoder_layers:\n",
        "            x = layer(x, src_mask)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def decode(self, tgt, encoder_output, tgt_mask=None, src_mask=None):\n",
        "        \"\"\"Decode target sequence\"\"\"\n",
        "        # Embedding + positional encoding\n",
        "        x = self.tgt_embedding(tgt) * math.sqrt(self.d_model)\n",
        "        x = self.pos_encoding(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Pass through decoder layers\n",
        "        attention_weights = []\n",
        "        for layer in self.decoder_layers:\n",
        "            x, attn_weights = layer(x, encoder_output, tgt_mask, src_mask)\n",
        "            attention_weights.append(attn_weights)\n",
        "\n",
        "        return x, attention_weights\n",
        "\n",
        "    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n",
        "        \"\"\"Forward pass for training\"\"\"\n",
        "        # Encode\n",
        "        encoder_output = self.encode(src, src_mask)\n",
        "\n",
        "        # Decode\n",
        "        decoder_output, attention_weights = self.decode(tgt, encoder_output, tgt_mask, src_mask)\n",
        "\n",
        "        # Project to vocabulary\n",
        "        output = self.output_projection(decoder_output)\n",
        "\n",
        "        return output, attention_weights"
      ],
      "metadata": {
        "id": "8KoSYqc1Nrlk"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_transformer(model, train_loader, val_loader, num_epochs=20, learning_rate=0.001):\n",
        "    \"\"\"Train the transformer model\"\"\"\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=2)  # Ignore padding tokens\n",
        "\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    print(f\"Training transformer for {num_epochs} epochs...\")\n",
        "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        num_batches = 0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            src = batch['src'].to(device)  # [batch_size, seq_len]\n",
        "            tgt = batch['tgt'].to(device)  # [batch_size, seq_len]\n",
        "\n",
        "            # Prepare target input and output\n",
        "            tgt_input = tgt[:, :-1]  # All but last token\n",
        "            tgt_output = tgt[:, 1:]  # All but first token\n",
        "\n",
        "            # Create causal mask for decoder\n",
        "            tgt_seq_len = tgt_input.size(1)\n",
        "            tgt_mask = model.create_causal_mask(tgt_seq_len).to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            optimizer.zero_grad()\n",
        "            output, _ = model(src, tgt_input, tgt_mask=tgt_mask)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(output.reshape(-1, output.size(-1)), tgt_output.reshape(-1))\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "        avg_train_loss = epoch_loss / num_batches\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        # Validation\n",
        "        val_loss = evaluate_model(model, val_loader, criterion)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch+1:2d}/{num_epochs}: Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "        # Early stopping\n",
        "        if avg_train_loss < 0.1:\n",
        "            print(\"Early stopping - good convergence achieved!\")\n",
        "            break\n",
        "\n",
        "    return train_losses, val_losses\n",
        "\n",
        "def evaluate_model(model, data_loader, criterion):\n",
        "    \"\"\"Evaluate model on validation set\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            src = batch['src'].to(device)\n",
        "            tgt = batch['tgt'].to(device)\n",
        "\n",
        "            tgt_input = tgt[:, :-1]\n",
        "            tgt_output = tgt[:, 1:]\n",
        "\n",
        "            tgt_seq_len = tgt_input.size(1)\n",
        "            tgt_mask = model.create_causal_mask(tgt_seq_len).to(device)\n",
        "\n",
        "            output, _ = model(src, tgt_input, tgt_mask=tgt_mask)\n",
        "            loss = criterion(output.reshape(-1, output.size(-1)), tgt_output.reshape(-1))\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "    model.train()\n",
        "    return total_loss / num_batches\n",
        "\n",
        "def translate_sentence(model, sentence, src_vocab, tgt_vocab, max_len=50):\n",
        "    \"\"\"Translate a single sentence\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Reverse vocabulary for decoding\n",
        "    tgt_idx_to_word = {idx: word for word, idx in tgt_vocab.items()}\n",
        "\n",
        "    # Tokenize input\n",
        "    words = sentence.lower().split()\n",
        "    src_tokens = [src_vocab.get('<SOS>', 0)]\n",
        "    for word in words:\n",
        "        src_tokens.append(src_vocab.get(word, src_vocab.get('<UNK>', 3)))\n",
        "    src_tokens.append(src_vocab.get('<EOS>', 1))\n",
        "\n",
        "    # Pad to max length\n",
        "    if len(src_tokens) < max_len:\n",
        "        src_tokens.extend([src_vocab.get('<PAD>', 2)] * (max_len - len(src_tokens)))\n",
        "\n",
        "    src_tensor = torch.tensor([src_tokens]).to(device)\n",
        "\n",
        "    # Encode\n",
        "    encoder_output = model.encode(src_tensor)\n",
        "\n",
        "    # Decode step by step\n",
        "    tgt_tokens = [tgt_vocab.get('<SOS>', 0)]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_len):\n",
        "            tgt_tensor = torch.tensor([tgt_tokens]).to(device)\n",
        "            tgt_mask = model.create_causal_mask(len(tgt_tokens)).to(device)\n",
        "\n",
        "            decoder_output, _ = model.decode(tgt_tensor, encoder_output, tgt_mask)\n",
        "            next_token_logits = model.output_projection(decoder_output[:, -1, :])\n",
        "            next_token = torch.argmax(next_token_logits, dim=-1).item()\n",
        "\n",
        "            if next_token == tgt_vocab.get('<EOS>', 1):\n",
        "                break\n",
        "\n",
        "            tgt_tokens.append(next_token)\n",
        "\n",
        "    # Convert back to text\n",
        "    translation = []\n",
        "    for token in tgt_tokens[1:]:  # Skip SOS\n",
        "        word = tgt_idx_to_word.get(token, '<UNK>')\n",
        "        if word not in ['<EOS>', '<PAD>']:\n",
        "            translation.append(word)\n",
        "\n",
        "    return ' '.join(translation)"
      ],
      "metadata": {
        "id": "5Y8TGDfiN2Jn"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TranslationDataset(Dataset):\n",
        "    \"\"\"Dataset for machine translation using TatoebaLoader format\"\"\"\n",
        "\n",
        "    def __init__(self, data_pairs, src_vocab, tgt_vocab, max_len=50):\n",
        "        self.data_pairs = data_pairs  # List of (src_text, tgt_text) tuples\n",
        "        self.src_vocab = src_vocab\n",
        "        self.tgt_vocab = tgt_vocab\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_text, tgt_text = self.data_pairs[idx]\n",
        "\n",
        "        src_tokens = self.tokenize_sentence(src_text, self.src_vocab)\n",
        "        tgt_tokens = self.tokenize_sentence(tgt_text, self.tgt_vocab)\n",
        "\n",
        "        return {\n",
        "            'src': torch.tensor(src_tokens, dtype=torch.long),\n",
        "            'tgt': torch.tensor(tgt_tokens, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "    def tokenize_sentence(self, sentence, vocab):\n",
        "        words = sentence\n",
        "        tokens = [vocab.get('<SOS>', 0)]\n",
        "\n",
        "        for word in words:\n",
        "            tokens.append(vocab.get(word, vocab.get('<UNK>', 3)))\n",
        "\n",
        "        tokens.append(vocab.get('<EOS>', 1))\n",
        "\n",
        "        # Pad or truncate\n",
        "        if len(tokens) > self.max_len:\n",
        "            tokens = tokens[:self.max_len]\n",
        "        else:\n",
        "            tokens.extend([vocab.get('<PAD>', 2)] * (self.max_len - len(tokens)))\n",
        "\n",
        "        return tokens"
      ],
      "metadata": {
        "id": "URepQu3yPZqY"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"SIMPLIFIED TRANSFORMER FOR MACHINE TRANSLATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create dataset using TatoebaLoader\n",
        "print(\"Creating dataset using TatoebaLoader...\")\n",
        "loader = OpusLoader()\n",
        "dataset = loader.prepare_training_data(max_pairs=100, vocab_size=300)\n",
        "\n",
        "train_data = dataset['train_data']\n",
        "val_data = dataset['val_data']\n",
        "src_vocab = dataset['src_vocab']\n",
        "tgt_vocab = dataset['tgt_vocab']\n",
        "src_idx_to_word = dataset['src_idx_to_word']\n",
        "tgt_idx_to_word = dataset['tgt_idx_to_word']\n",
        "\n",
        "print(f\"Training pairs: {len(train_data)}\")\n",
        "print(f\"Validation pairs: {len(val_data)}\")\n",
        "print(f\"Source vocabulary: {len(src_vocab)} words\")\n",
        "print(f\"Target vocabulary: {len(tgt_vocab)} words\")\n",
        "\n",
        "# Create data loaders\n",
        "train_dataset = TranslationDataset(train_data, src_vocab, tgt_vocab)\n",
        "val_dataset = TranslationDataset(val_data, src_vocab, tgt_vocab)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Initialize model\n",
        "model = SimplifiedTransformer(\n",
        "    src_vocab_size=len(src_vocab),\n",
        "    tgt_vocab_size=len(tgt_vocab),\n",
        "    d_model=64,          # Smaller embedding size as specified\n",
        "    num_heads=2,         # 2 attention heads as specified\n",
        "    num_encoder_layers=2, # 2 encoder layers as specified\n",
        "    num_decoder_layers=2, # 2 decoder layers as specified\n",
        "    d_ff=128,            # Reduced feedforward dimension as specified\n",
        "    dropout=0.1\n",
        ").to(device)\n",
        "\n",
        "print(f\"\\nModel created with {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
        "\n",
        "# Train model\n",
        "print(\"\\nTraining model...\")\n",
        "train_losses, val_losses = train_transformer(model, train_loader, val_loader,\n",
        "                                            num_epochs=15, learning_rate=0.001)\n",
        "\n",
        "# Test translations\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"TESTING TRANSLATIONS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "test_sentences = [\n",
        "    \"hello\",\n",
        "    \"thank you\",\n",
        "    \"good morning\",\n",
        "    \"i am hungry\",\n",
        "    \"the cat is sleeping\"\n",
        "]\n",
        "\n",
        "for sentence in test_sentences:\n",
        "    translation = translate_sentence(model, sentence, src_vocab, tgt_vocab)\n",
        "    print(f\"'{sentence}' â†’ '{translation}'\")\n",
        "\n",
        "# Save vocabularies for comparison with seq2seq model\n",
        "print(\"\\nVocabularies created for model comparison:\")\n",
        "print(f\"Source vocab sample: {list(src_vocab.items())[:10]}\")\n",
        "print(f\"Target vocab sample: {list(tgt_vocab.items())[:10]}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3S56O1K-N8cp",
        "outputId": "e208faab-36f1-4517-e540-cfff651676f2"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "SIMPLIFIED TRANSFORMER FOR MACHINE TRANSLATION\n",
            "============================================================\n",
            "Creating dataset using TatoebaLoader...\n",
            "Trying opus100 dataset...\n",
            "Loaded 100 pairs from opus100 dataset\n",
            "Source vocab size: 300\n",
            "Target vocab size: 300\n",
            "Training pairs: 80\n",
            "Validation pairs: 20\n",
            "Source vocabulary: 300 words\n",
            "Target vocabulary: 300 words\n",
            "\n",
            "Model created with 225,324 parameters\n",
            "\n",
            "Training model...\n",
            "Training transformer for 15 epochs...\n",
            "Model parameters: 225,324\n",
            "--------------------------------------------------\n",
            "Epoch  1/15: Train Loss: 2.9341, Val Loss: 1.5943\n",
            "Epoch  2/15: Train Loss: 1.3124, Val Loss: 0.7271\n",
            "Epoch  3/15: Train Loss: 0.5550, Val Loss: 0.2750\n",
            "Epoch  4/15: Train Loss: 0.2389, Val Loss: 0.1325\n",
            "Epoch  5/15: Train Loss: 0.1289, Val Loss: 0.0787\n",
            "Epoch  6/15: Train Loss: 0.0825, Val Loss: 0.0537\n",
            "Early stopping - good convergence achieved!\n",
            "\n",
            "==================================================\n",
            "TESTING TRANSLATIONS\n",
            "==================================================\n",
            "'hello' â†’ '<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>'\n",
            "'thank you' â†’ '<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>'\n",
            "'good morning' â†’ '<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>'\n",
            "'i am hungry' â†’ '<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>'\n",
            "'the cat is sleeping' â†’ '<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>'\n",
            "\n",
            "Training complete!\n",
            "Final train loss: 0.0825\n",
            "Final validation loss: 0.0537\n",
            "Total parameters: 225,324\n",
            "\n",
            "Vocabularies created for model comparison:\n",
            "Source vocab sample: [('<PAD>', 0), ('<SOS>', 1), ('<EOS>', 2), ('<UNK>', 3), ('.', 4), (\"'\", 5), ('-', 6), ('?', 7), ('i', 8), ('you', 9)]\n",
            "Target vocab sample: [('<PAD>', 0), ('<SOS>', 1), ('<EOS>', 2), ('<UNK>', 3), ('.', 4), (\"'\", 5), ('de', 6), ('Ã ', 7), ('?', 8), ('-', 9)]\n"
          ]
        }
      ]
    }
  ]
}